# Data Ethics Club: [The Political Economy of Death in the Age of Information: A Critical Approach to the Digital Afterlife Industry](https://link.springer.com/article/10.1007/s11023-017-9445-2)
```{admonition} What's this? 
This is summary of Wednesday 2nd April’s Data Ethics Club discussion, where we spoke and wrote about the article [The Political Economy of Death in the Age of Information: A Critical Approach to the Digital Afterlife Industry](https://link.springer.com/article/10.1007/s11023-017-9445-2) by Carl Öhman and Luciano Floridi.
The summary was written by Jessica Woodgate, who tried to synthesise everyone's contributions to this document and the discussion. "We" = "someone at Data Ethics Club". 
Huw Day helped with the final edit.
```

## Article Summary

Around 2004, sociologists began to notice that people were interacting through digital means to remember or communicate with deceased loved ones. Where people may previously have written journals to deal with their grief, they were now writing blogs. Today, in the agent of artificial intelligence (AI), there is some sense in which people can “communicate” with digital replicas of their loved ones. As our relationship with digital media evolves and our data footprints grow larger, considering what happens to our digital presence after death becomes increasingly important. 

The paper critically examines the concept of digital afterlife and the role of commercial interests in shaping it, adopting a political-economic perspective to coin the concept of the Digital Afterlife Industry (DAI). The DAI consists of a range of actors, from small start-up applications to technological giants, that offer commercial services to mediate the online presence of the dead. The DAI is defined using three necessary and sufficient criteria: production, in that some form of goods or services are produced; commercialism, as goods or services are produced for the purpose of making profits (producing commodities); online usage of digital human remains, using any informational content left by the deceased online.

Commodifying digital human remains is problematic because of the inherent right to control one’s personal identity. People do not just own their information but are constituted by it and exist through it – an idea adapted from [Floridian](https://scholar.google.co.uk/citations?user=jZdTOaoAAAAJ&hl=en&oi=ao) ethics. Our information and personal data are our informational bodies in that they are “ours” in the sense of “our body” rather than “our car”. From a [Marxian](https://scholar.google.co.uk/citations?user=4VSRHmIAAAAJ&hl=en&oi=ao) perspective, the labour that one produces – one’s “inorganic body” - is an instantiation of oneself and objectifies one’s inner nature. When one loses control over what one produces (e.g. when it is commodified), one loses control over one’s inorganic body, and thereby also of oneself. In the realm of the DAI, the estrangement of one’s inorganic body takes place after death, wherein digital afterlife services have an incentive to shape digital remains according to what is profitable and consumable. Taking control of one’s informational or inorganic body, which is the essence of the human condition, is an aggression to human dignity; of remaining master of one’s existence. 

Over the years, there have been wide-ranging discussions on the ethical implications of DAI, including how to drive governance (entailing not just legal regulation, but also ethics and policy) by responsible innovation. The paper argues that the digital remains of the dead deserve the respect worthy of a human body, rather than being treated as instruments for revenue generation. While all services have economic incentives to maximise production, they should not maximise production in every way possible. 

## Discussion Summary

### Of the different kinds of services within DAI (section 3.1, page 6; Information Management Services, Posthumous Messaging Services, Online Memorial Services and Re-creation Services); Which have you encountered? Which are you ok with? Which would you use? Which do you want to ban or heavily regulate?

Our encounters with aspects of DAI have mainly come through various kinds of Facebook interactions. We’ve seen some accounts end up as “ghosts”, where there is no activity, but the page is still there. These ghost pages have led us to identify accounts that have been hacked, after receiving messages from people that have died. We have seen different versions of how memorial profiles have been handled, such as being tagged on anniversaries with “still missing you” types of messages.  Early versions of “recreation” services would take a picture of someone and animate it. 

We’ve encountered the information management side of things, when relatives have had to look after the deceased’s account. Sometimes this ends up with the page being requested to be deleted. The Google inactive account manager is quite useful to help handle these scenarios; it even applies when you’re still alive, as everybody ends up with an inordinate number of accounts. Similar issues of information management also take place outside of Facebook, for instance, we’ve been executors of family members’ estates, where the family member died of a rare disease. We were given no opportunity to discuss with the hospital whether there is an option to share data of the rare disease or delete the data depending on the wishes of the dead.

Caring for people’s wishes regarding their informational bodies was much easier before social media became more popular. Social media is dependent on the data that people put on there; mechanisms are not designed in a way as that makes it easy to remove your informational body, especially if you have died. It is simplest, and potentially more profitable, for businesses to leave the information of dead people up. Running out of data storage is likely to be the biggest hurdle in maintaining all of the information. On a practical level, we wondered how easy it is to completely remove someone’s record from social media, as it will include multitudinous references to them through various different means such as messaging, photographs, or sharing posts.

It’s likely that social media platforms were not explicitly thinking of this issue when they began, and the way we interact with them gives them jurisdiction over our data. When Facebook started, it was to link up with friends; sharing photographs and more complex information came later. We may think that as the data has been willingly volunteered to the platforms, they have a right to claim it. If someone gave you their socks, and then died, you would still think of them as your socks. When sending your work to a publisher you agree that publisher can make money from it and will continue to make money from it after you die. Similarly, one could argue that uploading posts to social media is done with the knowledge that platforms make money from that data. However, the social contract between a publishers and Facebook page seems conceptually different: you sign a rights agreement with a publisher, but you do not with Facebook.

Discerning whether someone has given consent for their informational body to be used or changed is very dependent on that person explicitly considering the topic before they die, which is not often the case. Understanding how people want to be celebrated is not always straightforward, for instance, if a friend says they do not want a birthday party, you may still buy them a card despite the indication they don’t want to celebrate. If someone says they don’t want a funeral, sometimes a funeral may still be held, as an opportunity for the living to grieve.

When discussing the most appropriate way to treat people that have died, there are two main camps: one arguing that the dead can’t be harmed; another arguing that the dead should be protected. Many of us have the intuition to protect someone after they have died. For those of us who have had family members pass, we have seen motivation to protect from different perspectives: the hospital performing duties of care, and the executors attempting to find out missing information about the person after their death.

It is no longer in your control what happens to your information after your death, and that can feel troubling. We go through life fairly in control over what we put online, but after you pass you don’t know what people will share in obituaries, on social media, or elsewhere. The lack of control is perhaps exacerbated on social media where there is no clear succession of your profiles. There is an option on Facebook to turn profiles into “remembrance” profiles, but people might not want it to be that easy for others to find out they have died. It feels strange that people can post things about you on social media if you die, yet nobody can control or remove those posts for you. If family members were granted access to your profiles, they may see things that the deceased didn’t want to share, or the family themselves may want to remove some of the deceased’s information from the public. Family and friends may struggle to control the narrative; [Elaine Kasket](https://www.elainekasket.com/) discusses where people have been murdered and photographs of them with an ex-boyfriend or friends who did not want to be in the public eye have been lifted from their social media platforms and published. The storyline of [Adolescence](https://en.wikipedia.org/wiki/Adolescence_(TV_series)), a TV series about teenage murder, [completely sidelines the victim and her family - something often replicated in real life murders](https://www.linkedin.com/pulse/adolescence-child-violence-adults-issue-policybristol-wbrie/?trackingId=1b1cH5MhwfY3yrQ6xAKWVw%3D%3D).

Whilst respecting human dignity of those who have passed is important, placing too much emphasis the issue may over-value one person’s data and privilege individual rights over public good. Data is valued in aggregate, so one person’s specific data, such as their Facebook profile, may not carry much weight. Being able to share data can benefit common interests, for example, in the health care sector there could be valuable insights gained from the data.

In the current climate, however, there may not be institutions that are both trustworthy and have the resources to look after the data. Big pharma companies are well-resourced, but it is difficult to trust them, whereas public hospitals and health services are trustworthy but don’t have the resources to handle the data. We would be interested to see a critical overview comparing data handling in large private pharmaceutical companies and public health bodies such as the NHS. The NHS has a [transparent records retention protocol](https://transform.england.nhs.uk/information-governance/guidance/records-management-code/#service_user) with a minimum length of time that records should be maintained, after which they are usually disposed of. It is less clear how health records are handled in private companies, such as 23&me (see our [previous Data Ethics Club](https://dataethicsclub.com/write_ups/2024-11-20_writeup.html)), apple watches, or even in military contexts.

Thinking about how companies treat our information and adopting an economic view of the issue is quite an interesting approach. An economic perspective frames the problem within a large setting that explains causes and incentives for the phenomena, as well as the social repercussions. We found it uncomfortable that people would still be capitalising on our social media presence after we have died. The business model strikes us as weird: dead people can’t spend money. Nevertheless, we can imagine some of the larger tech firms cashing in on it.

Thinking more abstractly about what would happen in the future if big tech companies were to cash in on the concept of a digital afterlife, we were reminded of the [Culture](https://en.wikipedia.org/wiki/Culture_series) book series by Iain M. Banks. The series explores the concept of societies creating “Heavens” by transferring the consciousness of dead people into a server cultivated to portray the heaven of the dominant religion of  the society. [Surface Detail](https://en.wikipedia.org/wiki/Surface_Detail) is a later book in the series that explores the corollary of this: if people can create heavens, they can also create hells.

### The paper focusses a lot on the potential for DAI to threaten/violate human dignity - what other concerns would like to be highlighted in the discussion of these “technologies”?

In conjunction with the dignity of those who have died, ethical considerations relevant to the DAI include the effects of digital afterlife on the grieving process. If a chatbot is trained to imitate someone who has died, it could impede loved ones from moving on as they may not want to “let go”. The ethics of chatbots and risks of exploiting vulnerable people was [explored in a previous Data Ethics Club](https://dataethicsclub.com/write_ups/2024-02-14_writeup.html). Chatbot services that are paid for further amplify potential harms, as companies are incentivised to increase engagement, which may thereby encourage unhealthy behaviours. [Studies have found grieving complications to be linked to substance abuse](https://pmc.ncbi.nlm.nih.gov/articles/PMC7848780/), and we thought it likely that addictive tendencies are magnified in those that are grieving. People may become addicted to DAI services, or those services could feed other addictive behaviours.

DAI products may obstruct people from being able to express and resolve their emotions in healthy ways. At a funeral, if someone is completely distraught or being unreasonable, we would take them away from the group into a quiet place where they can calm down. Online, there is nothing to stop them from issuing a torrent of comments, which may be overwhelming for others. It could be deeply disturbing for loved ones to see a chatbot regurgitating uncanny valley type content that is attempting to mimic the deceased. Even if it is rubbish, or perhaps especially if it is very good, it seems deeply infringing for chatbots to pretend to be people that have died.

The reception of such chatbots and other DAI products may change according to particular cultures. Different cultures have different customs for treating bodies and memorialising people. For example, [in the US it is very common to write obituaries that focus on someone’s personal achievements; in Japan, obituaries tend to focus on more concise attributes of a person such as their name, age, and family members](https://ohmyfacts.com/culture-art/20-facts-about-obituaries-across-cultures/). Certain faiths consider suicide to be a real taboo, which may affect how  people react online.

### How would you regulate these technologies in a way which respects individual autonomy, the wishes of their loved ones and accounting for rapid development of technology in this area?

To inform regulation of DAI technologies, one could examine how people have reacted historically to various advances in technology that have had an influence on death and the grieving process. For instance, capturing people’s images through photography, the printing process, or even art. Today, we wouldn’t consider an old photograph or recording of a dead loved one to be an infringement on their dignity. Yet when these technologies first entered into society, it must have been quite disturbing to listen to and see people that have died. Perhaps the DAI is just the next progression, and it feels uncomfortable because it is new. People now hold concerts replicating people that have died, such as the [Tupac hologram at Coachella](https://www.npr.org/sections/therecord/2012/04/17/150820261/how-that-tupac-hologram-at-coachella-worked), and hold seances on TikTok. Yet, these kinds of events seem to reflect more of a fascination with death, rather than ways of coping with grief. 

There does seem to be an important difference between previous advancements in artificially representing people and the DAI; a photograph of someone is conceptually different to a chatbot mimicking them. With DAI services, there are risks that arise with the potential for unhelpful information being conveyed, such as fabricated communication from a dead relative via a séance on TikTok, or an LLM hallucinating. This may give rise to opportunities for malicious actors to harness DAI products for exploitative purposes.

Capacity to exploit the deceased may depend on one’s digital footprint. We know people that only have a couple of pictures on their social media profiles, which is not enough to enable deepfakes or replicate them in a chatbot. In the new economy of death, maybe people would pay for companies to fill out missing parts to recreate their loved ones. The paper explores how social media allows users to employ celebrity-like strategies of communication. As users are given the opportunity to have an audience and recorded life, a privilege previously only granted to celebrities, people now have the opportunity for celebrity-like afterlives. Yet, we see a big difference between digital celebrities and the rest of us.

In order to properly legislate and regulate the DAI, governments would in some sense have to answer the theory of embodiment. After you die, some of us think that your body isn’t really “your” body, as “you” aren’t there anymore. In this sense, digital afterlife might even be more problematic than desecrating physical corpses, as there is some sense of personhood or a mind tied in. 

It is also important to discern if digital afterlife is more akin to physical bodies or intellectual property. The first three types of digital afterlife in the paper (information management; posthumous messaging; online memorial) could be conceived as being similar to intellectual property. The fourth type of digital afterlife, recreation, feels different to the other services. Recreation seems much closer to infringing on a person’s dignity and rights to their body or mind. If it is treated like intellectual property, there might be emotional risks attached as it could feel depersonalising. Identifying the important variable for producing an emotional reaction isn’t straightforward, for example, it is possible to be deeply moved by a painting even without connection to its subject. 

In some countries, there is the idea of inheritable property which could perhaps be expanded to encompass peoples’ informational bodies. However, regulation should be strict so that models are not profitable, and the wellbeing of the family members is the primary incentive. If a couple who had lost a child wanted to recreate their child as closely as possible, for example, we might see some justification in this. Digital afterlife material may also outlive all loved ones that new the person, so those situations would need to be handled too.

Existing regulation that could be relevant is GDPR, which doesn’t currently apply to the dead, so the “right to be forgotten” does not apply. However, maybe people should be able to request the right to be forgotten upon event of their death. To roll this out, we would need to discern what the default option would be; whether it would be to opt in or opt out. GDPR should be considered in conjunction with existing regulation surrounding death, as the DAI isn’t completely new, but part of a pre-existing, relatively large industry, i.e., the funeral industry.

## Attendees

- Huw Day, Data Scientist, University of Bristol: [LinkedIn](https://www.linkedin.com/in/huw-day/), [BlueSky](https://bsky.app/profile/huwwday.bsky.social)
- Amy Joint, Programme Manager, BMC (the publisher, not the British Mountaineering Council) [LinkedIn](https://www.linkedin.com/in/amyjoint)
- Euan Bennet, Lecturer, University of Glasgow, [BlueSky](https://bsky.app/profile/dreuanbennet.bsky.social)
- [Kamilla Wells](https://www.linkedin.com/in/kamilla-wells/), Citizen Developer, Australian Public Service, Brisbane
- [Robin Dasler](https://www.linkedin.com/in/robindasler), Data Product Manager, California
- Beverly Shirkey, Medical Statistican in clinical trials, University of Bristol
- Joe Carver, Data Scientist, Brandwatch
