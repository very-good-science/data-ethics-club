---
blogpost: true
date: January 21st, 2026
author: Jessica Woodgate
category: Write Up
tags: datacentres, sustainability, generative AI, statistics
---

# Data Ethics Club: [Global datacentre electricity consumption is not correlated with data demand: Responding to implausible assumptions and flawed modelling in Castro et al. (2024)](https://www.sciencedirect.com/science/article/pii/S0301421525004549)

<!--
```{admonition} What's this? 
This is summary of Wednesday 21st January's Data Ethics Club discussion, where we spoke and wrote about the article [Global datacentre electricity consumption is not correlated with data demand: Responding to implausible assumptions and flawed modelling in Castro et al. (2024)](https://www.sciencedirect.com/science/article/pii/S0301421525004549) by Daniel Schien, Adrien Berthelot, Paul Shabajee, and Chris Preist.
The summary was written by Jessica Woodgate, who tried to synthesise everyone's contributions to this document and the discussion. "We" = "someone at Data Ethics Club". 
Huw Day helped with the final edit.
```
-->

## Article Summary

The paper [Digital data demand and renewable energy limits: Forecasting the impacts on global electricity supply and sustainability (Castro et al., 2024)](https://www.sciencedirect.com/science/article/pii/S0301421524004245) explores the concern that the energy required for digital data could eventually exceed what can be feasibly produced. Whilst Castro et al. (2024) tackles an issue which is increasingly critical to society, Schien et al. (2025) argue that the assumptions and methodological choices made in the paper are flawed. Data used for analysis are outdated and inappropriate, and the dynamics of datacentre energy are mischaracterised. In particular, Schien et al. (2025) question the assumption that datacentre energy consumption is proportional to aggregate data demand. Schien et al. (2025) argue that these errors have resulted in predictions which are two to three orders of magnitude out, not just with predictions for the future but also with current values.

In brief, the method used by Castro et al. (2024) to estimate the development of global annual energy consumption of datacentres since 2011 is: extrapolate from Facebook’s reported total energy use in 2011; divide by the estimate data volume for Facebook transported through networks in 2012; and then multiply by the amount of data created, consumed, and stored. Schien et al. (2025) identify two key issues with this approach. Firstly, by using data from 2011, the method ignores exponential improvements in digital technology such as from the benefits of [Moore’s law](https://en.wikipedia.org/wiki/Moore%27s_law) and [Koomey’s law](https://en.wikipedia.org/wiki/Koomey%27s_law). Secondly, the paper assumes that datacentre energy use is correlated with the volume of data transmitted. However, this is inaccurate as energy consumption of data processing varies significantly between workloads and their utilisation of datacentre architectural components.

To advance research and understanding about datacentre energy demands, Schien et al. (2025) suggest that we improve understanding of the energy implications of specific types of data use and examine the growth of resource consumption rather than the growth of data. Castro et al. (2025) have since posted a [reply to Schien et al. (2024)](https://www.sciencedirect.com/science/article/pii/S0301421525004707) clarifying their approach and addressing critiques.

## Discussion Summary

### Do you think that power usage by datacentres should be made public record? Is this practical?

Practical hurdles in predicting energy use include dynamic energy requirements and opaqueness of information, which reduce the potential to accurately reason about future energy efficiency of data related technologies. Schien et al. (2025) highlight that different parts of data related processes have different energy requirements. For example, a training run for an individual AI algorithm can speed up or slow down at various points which may alter power consumption. There could also be points in time where training frequency increases and thereby spikes power usage, for example, if a company is developing a new product. Distinguishing between the energy costs of different data related processes is challenging if the information is not monitored and shared by companies deploying those processes. 

Currently, datacentre energy consumption is not made transparent by datacentre providers or AI companies and it seems unlikely that this information will be easily volunteered. Companies benefit from the opaqueness of their power usage as it shields them from criticism. As the primary motivation of a commercial enterprise is to create profit, companies are not inherently motivated by sustainability concerns. Sustainability only becomes important through external pressures such as public backing behind particular causes. Other channels to access energy consumption data could be via the energy providers, who at least in theory have access to this information. In some places, freedom of information requests could be filed. 

Discerning whether we should require energy usage of data processeses to be made openly available depends on when it becomes a matter of public interest. People should be able to fact check claims that are made to them, such as an energy company justifying increased costs due to excess demand from data centres. Transparency of consumption data would enable people to evaluate the truth of these claims, which is important because whilst it is well known that energy consumption in general is going up, we first need to understand the trajectory that we are on before we can actualise change. Altering the public perception of AI energy consumption could change how people interact with AI systems and encourage people to use AI more consciously.

Even if we do not have access to all the information about energy consumption and even if the claims in Castro et al. (2024) are incorrect, there is still much to be critical of. The lower estimates of usage in Castro et al. (2024) are still quite high. Energy is also not the only important resource being used by datacentres. Datacentres [occupy large areas of land](https://www.techtarget.com/searchdatacenter/feature/The-increasing-concern-of-data-center-land-acquisition), with the average datacentre covering 100,000 square feet. Datacentres can also [cause noise pollution and needs to be well-connected to relevant infrastructure](https://dataethicsclub.com/write_ups/datacentres.html#development-considerations).

### How much are debates/misunderstandings on datacentre power usage polarised by existing positions on environmental issues/generative AI?

Alarmist claims about power consumption of data and AI are not helpful as they reduce the credibility of legitimate criticisms. Flaws in research and public discussion are perhaps seeded by deficiencies in cross-disciplinary method and information sharing. Cross-disciplinarity is especially important from a policy perspective, where diverse viewpoints need to be taken into account to reach informed conclusions. We wondered whether policymakers need to be subject experts, or whether it is better to have people with broad overviews of a range of topics. Regulators are in an unenviable position of having to make sense of a technological space which is evolving extremely rapidly.

Debates about datacentres need to consider the politicised nature of the space. Datacentres form a key part of the government’s plan for economic growth as they have been [designated Critical National Infrastructure (CNI)](https://www.gov.uk/government/news/data-centres-to-be-given-massive-boost-and-protections-from-cyber-criminals-and-it-blackouts) and articles about datacentres are frequently in newspaper headlines. Motivated by the potential of AI to harvest productivity gains, the political will seems set towards [taking a frontrunner place in AI development and “turbocharging” growth](https://www.gov.uk/government/news/prime-minister-sets-out-blueprint-to-turbocharge-ai). Datacentre development is being [fast tracked and planning regulations dissolved](https://dataethicsclub.com/write_ups/datacentres.html#planning-reforms), aided by the incorporation of datacentre development in the [Nationally Significant Infrastructure Projects (NISPs)](https://www.gov.uk/government/consultations/proposed-reforms-to-the-national-planning-policy-framework-and-other-changes-to-the-planning-system/outcome/government-response-to-the-proposed-reforms-to-the-national-planning-policy-framework-and-other-changes-to-the-planning-system-consultation).

The trade-off between desire for economic growth and environmental concerns illuminates a core feature of datacentre debates: they are debates on values, which means that they are not necessarily rational. People participating in these debates have vested interests in the outcomes. Those who work with AI and want to create systems with it will find reasons that justify it being good to do so. Those wanting to protect the environment or who are anti-AI for other reasons may not see the value in prioritising economic gain over different concerns.

An accurate picture of datacentres needs to incorporate the wider systemic context and how we have reached the position where we are today. The rapid and widespread adoption of generative AI, with its reliance on datacentre infrastructure, have led to much more public discussion around datacentres in recent years. However, it is important to bear in mind that datacentres are not new and have been [around since the 1950s](https://www.trgdatacenters.com/resource/history-of-data-centers/) to support technical infrastructure.

### How should academics handle these sorts of disagreements?

The credit and weight of academic writing is facing serious challenges as peer review struggles to keep up with [massive increases in the volume of submissions to publication venues](https://direct.mit.edu/qss/article/5/4/823/124269/The-strain-on-scientific-publishing) and global cuts to research funding. Peer review relies on academics being able to dedicate their time without external funding. Yet, the workloads and pressure mounted on academics is growing ever larger, making it challenging to fulfil all the demands placed upon them.

### What change would you like to see on the basis of this piece? Who has the power to make that change?

As the overarching political will in the UK is to boost productivity gains and economic growth, our individual agency to affect energy consumption is very limited. It is disingenuous to say that individuals are able to influence environmental impacts by deciding whether or not to use generative AI. In a stable economy, deciding not to use generative AI could influence the development of datacentres. Yet because datacentre building is speculative, this is not the case. Basing datacentre development on projections of future use makes it difficult to reason about energy efficiency of the technology a few years down the line. This is a risk for companies, as it means that we are locking ourselves in with demand profiles for datacentres.

For those of us who do use generative AI, we found this explanation of the limits of individual responsibility very helpful. We wondered how, considering that the problem is predominantly on a systematic level, we can stop things from getting worse. In general, if you care about sustainability there are actions you can take to meaningfully reduce your resource usage. For example, if you care about water consumption, you can have shorter showers or not flush your toilet as often. The leverage you get from deciding not to send emails or take photographs, however, doesn’t do much to conserve water. Instead, one of the best things individuals can do is make sure that they use suppliers who focus on sustainable energy. We need to prioritise decoupling our energy consumption with carbon and give precedence to more sustainable fuel sources.

## Attendees
- Huw Day, Data Scientist, University of Bristol: [LinkedIn](https://www.linkedin.com/in/huw-day/), [BlueSky](https://bsky.app/profile/huwwday.bsky.social)
- [Jessica Woodgate](https://jessica-woodgate.github.io/), PhD Student, University of Bristol
- Uttam Singh (MSC Data Analytics), Business Intelligence Analyst, NHS Trust, working on Data Science Projects and enjoy reading philosophy
- Pippin Sadler, Data Analyst
- Ismael Kherroubi Garcia, AI Ethics Consultant: [Bluesky](https://bsky.app/profile/hermeneuticist.bsky.social), [LinkedIn](https://www.linkedin.com/in/ismaelkherroubi/)
- Denise Tampieri ex BCG Data Scientist (MSc in Data and AI ethics in Edinburgh): [LinkedIn](https://www.linkedin.com/in/denisetampieri2000)
- Joe Carver, Data Scientist, Brandwatch
- Robin Dasler, data software product manager on hiatus, California
- Bing Wang, Senior Analyst, Guys and St Thomas NHS Foundation Trust, configurate electronic patient records.
