
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Data Ethics Club discusses We created poverty. Algorithms won’t make that go away (28th Apr 21) &#8212; Data Ethics Club v0.1.0 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="dataethicsclub.com/contents/write_ups/2021/28-04-21_writeup.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Data Ethics Club discusses: UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape (14th Apr 21)" href="14-04-21_writeup.html" />
    <link rel="prev" title="Data Ethics Club discusses Critical perspectives on Computer Vision (12th May 21)" href="12-05-21_writeup.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../../index.html">
<p class="title">Data Ethics Club</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../join_in/join_in.html">
  Join in
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../reading-list.html">
  Reading list
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../write-ups.html">
  Write-ups
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../how_to/reuse_dec.html">
  Reuse our materials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../contact.html">
  Contact us
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../mailing-list.html">
  Mailing list
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/very-good-science/data-ethics-club" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/hashtag/DataEthicsClub" rel="noopener" target="_blank" title="Twitter"><span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this site..." aria-label="Search this site..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../2022/06-04-22_writeup.html">
   Data Ethics Club: The Algorithmic Colonization of Africa
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2022/23-03-22_writeup.html">
   Data Ethics Club: The Tyranny of Structurelessness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2022/09-03-22_writeup.html">
   Data Ethics Club: AI in Warfare
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2022/09-02-22_writeup.html">
   Data Ethics Club: “You Social Scientists Love Mind Games”: Experimenting in the “divide” between data science and critical algorithm studies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2022/26-01-22_writeup.html">
   Data Ethics Club: Which Programming Languages Use the Least Electricity?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2022/12-01-22_writeup.html">
   Data Ethics Club: Resolutions 2022
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15-12-21_writeup.html">
   Data Ethics Club: A Question of Trust
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17-11-21_writeup.html">
   Data Ethics Club: Statistics, Eugenics and Me
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03-11-21_writeup.html">
   Data Ethics Club: UK National AI Strategy: Pillar 3 - Governing AI Effectively
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20-10-21_writeup.html">
   Data Ethics Club: Towards decolonising computational sciences (20th Oct 2021)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-10-21_writeup.html">
   Data Ethics Club: Structural Injustice and Individual Responsibility (6th Oct 2021)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08-09-21_writeup.html">
   Data Ethics Club: ESR: Ethics and Society Review of Artificial Intelligence Research (8th Sept 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="25-08-21_writeup.html">
   Data Ethics Club: “Participant” Perceptions of Twitter Research Ethics (25th Aug 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11-08-21_writeup.html">
   Data Ethics Club: What an ancient lake in Nevada reveals about the future of tech (11th Aug 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="28-07-21_writeup.html">
   Data Ethics Club: The Rise of Private Spies (28th July 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14-07-21_writeup.html">
   Data Ethics Club discusses The mathematics of crime and terrorism (14th July 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="26-05-21_writeup.html">
   Data Ethics Club discusses ‘Living in the Hidden Realms of AI: The Workers Perspective’ (26th May 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12-05-21_writeup.html">
   Data Ethics Club discusses Critical perspectives on Computer Vision (12th May 21)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Data Ethics Club discusses We created poverty. Algorithms won’t make that go away (28th Apr 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14-04-21_writeup.html">
   Data Ethics Club discusses: UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape (14th Apr 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="31-03-21_writeup.html">
   Data Ethics Club discusses Dataism Is Our New God (31st March 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17-03-21_writeup.html">
   Data Ethics Club discusses “#bropenscience is broken science” (17th March 21)
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#intro">
   Intro
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-deserving-of-help-are-we-is-this-a-reasonable-question-or-is-it-just-uncomfortable">
   How deserving of help are we? Is this a reasonable question (or is it just uncomfortable)?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-projects-that-involve-direct-impacts-on-people-s-lives-does-everything-need-to-be-automated-and-optimised">
   In projects that involve direct impacts on people’s lives, does everything need to be automated and optimised?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-what-ways-can-data-scientists-positively-contribute-fair-algorithmic-decision-making">
   In what ways can data scientists positively contribute fair algorithmic decision-making?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#closing-thoughts">
   Closing thoughts
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#voting">
   Voting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#contributors">
   Contributors:
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="data-ethics-club-discusses-we-created-poverty-algorithms-won-t-make-that-go-away-28th-apr-21">
<h1>Data Ethics Club discusses <a class="reference external" href="https://www.theguardian.com/commentisfree/2018/may/13/we-created-poverty-algorithms-wont-make-that-go-away">We created poverty. Algorithms won’t make that go away</a> (28th Apr 21)<a class="headerlink" href="#data-ethics-club-discusses-we-created-poverty-algorithms-won-t-make-that-go-away-28th-apr-21" title="Permalink to this headline">#</a></h1>
<div class="admonition-what-is-this admonition">
<p class="admonition-title">What is this? </p>
<p>This is summary of Wednesday 28th April’s Data Ethics Club discussion, where we spoke and wrote about the piece <a class="reference external" href="https://www.theguardian.com/commentisfree/2018/may/13/we-created-poverty-algorithms-wont-make-that-go-away">“We created poverty. Algorithms won’t make that go away” </a>, which is an article written by Virginia Eubanks, author of “Automating Inequality”. As one of the attendees pointed out, the article was in some senses a summary of some of the ideas from the book, which comes highly recommended!</p>
<p>The summary was written by Huw Day, who tried to synthesise everyone’s contributions to this document and the discussion. “We” = “someone at Data Ethics Club”.</p>
</div>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<p>Algorithms are being deployed to decide who can access scarce public resources.</p>
<p>We are constantly making personal decisions about resource allocation - do you deserve takeout tonight?
A day off next week?
A holiday this year?
In doing so, we consider available resources (both our own and those of others), expected payoff and how deserving we are.
No algorithm required.</p>
<p>Are algorithms just shields for people to hide behind?
When used in that way, is AI decision-making fundamentally different to using people or government departments as the scapegoat for failures instead?</p>
<p>You can’t fix the problem of not enough resources with distributing those resources more “efficiently”, but does that mean you shouldn’t try?</p>
</section>
<section id="intro">
<h2>Intro<a class="headerlink" href="#intro" title="Permalink to this headline">#</a></h2>
<p>In <a class="reference external" href="https://www.theguardian.com/commentisfree/2018/may/13/we-created-poverty-algorithms-wont-make-that-go-away">this piece from The Guardian</a>, Virgina Eubanks shares her experiences of travelling the United States to study and write about the impact of hi-tech tools on public service programs.
She notes: “We are increasingly turning to digital tools to rank and rate which struggling families most deserve support.”</p>
<p>Since the ethical dilemmas are plentiful when attempting to share out insufficient resources among many needing and deserving causes, someone has to make the difficult decision as to what (and perhaps more crucially, who) constitutes a more or less “deserving” cause.
As Eubanks puts it, this task is of ranking deservingness is being outsourced to algorithms because “humans know better”.
Deceptively though, this means that whoever designs the algorithms gets to decide what the metrics are for “deservingness” - and surely they should know better?</p>
</section>
<section id="how-deserving-of-help-are-we-is-this-a-reasonable-question-or-is-it-just-uncomfortable">
<h2>How deserving of help are we? Is this a reasonable question (or is it just uncomfortable)?<a class="headerlink" href="#how-deserving-of-help-are-we-is-this-a-reasonable-question-or-is-it-just-uncomfortable" title="Permalink to this headline">#</a></h2>
<p>We can all understand the potential benefit of efficiency in decision-making.
However, it’s one thing to optimise the distribution of sufficient resources, and another to allocate insufficient resources to the most “deserving” cause.</p>
<p>Any form of optimising requires choosing parameters to optimise and this evaluation will inevitably be done from an outsider’s perspective.
If we put these optimisation decisions in the hands of technology, we need to ask if they are effective in reducing harm.
If they are ineffective, then it adds insult to injury because in addition to making the situation worse, you’re paying for it.</p>
<p>Meritocracy is often a story the successful tell about themselves, forgetting their starting advantages and luck along the way.
In contrast, blame is placed on the unsuccessful for perceived “failure”.
This means “deservingness” may be exactly the wrong lens to look through.</p>
</section>
<section id="in-projects-that-involve-direct-impacts-on-people-s-lives-does-everything-need-to-be-automated-and-optimised">
<h2>In projects that involve direct impacts on people’s lives, does everything need to be automated and optimised?<a class="headerlink" href="#in-projects-that-involve-direct-impacts-on-people-s-lives-does-everything-need-to-be-automated-and-optimised" title="Permalink to this headline">#</a></h2>
<p>When resources are inadequate, inefficient distribution of what resources there are is unlikely to help persuade politicians or other decision makers to increase the resources.
This decreases the opportunity for creative solutions that are not accounted for in the parameters.
Applying an algorithmic solution to a resource management problem has the external appearance of a “fix” whilst hiding the fact that the best “fix” is to have more resources.</p>
<p>If you have three people and two chairs, you can run a complex algorithm to decide who is most deserving of a seat at the table based on medical historical, gym memberships and perhaps how altrusistic each person is. Or you could just get a third chair?</p>
<p>However, these impossible decisions about resource allocation are the day-to-day reality of many public sector services and local government.<br />
As a result they are continually being pitched software solutions to “smartify” certain processes by tech companies coming from the outside and not understanding how local government works.
These can be very expensive and well-marketed but unless their resource saving utility over the original system exceeds the costs of implementation, you are inevitably making a loss in the short term and reducing your already inadequate resources.</p>
<p>Algorithmic decision making is not all bad news. Consider the issue of food waste; automation and optimisation could do a great deal of good there.
But do these optimisations give us a free ride to avoid looking at other deeper issues e.g. dumpster locking/participation?
Algorithms can’t fix everything, but sometimes it is possible that they can ensure the most vulnerable get more help they would get from human decisions.
If there isn’t a third chair and an algorithm can make a fairer choice than a human, perhaps algorithms have their place in decision-making after all.
Crucially, it is often unclear which situation we are in.</p>
<p>Even if we were to know that the resources are being more efficiently allocated on average, we also want to ensure that they are not benefiting certain groups over others.</p>
<p>There is also a distinction to be made between “automated” and “digital”.
Automating a task to free up resources can often be more cost effective than getting a person to do it, but potentially at the cost of taking a vital input of human empathy out of the decision making.
Digitising a process is simply moving from information into a form that can be read, stored and processed by a computer.
Digitising a task both increases the scope of automation but also potentially allows a human decision maker to more easily consider all the variables at play in their decisions.</p>
<p>In general, we need more empathy in our decision making and should not forget to be human when that’s the better answer to the challenges we face.</p>
</section>
<section id="in-what-ways-can-data-scientists-positively-contribute-fair-algorithmic-decision-making">
<h2>In what ways can data scientists positively contribute fair algorithmic decision-making?<a class="headerlink" href="#in-what-ways-can-data-scientists-positively-contribute-fair-algorithmic-decision-making" title="Permalink to this headline">#</a></h2>
<p>Often data scientists choose to work on areas like poverty because they want to use their technical skills to help.
However, doing that alone could cause more harm than good.</p>
<p>It’s not possible to “outsource our ethical choices to machines”, because machines can’t make ethical choices, the ethical choices are made by the humans in the way they implement system.
This means we must take responsibility for these choices as we make them.
Similarly, we should do what we can to ensure anyone who uses our code understands that they take on the responsibility for how it is deployed.</p>
<p>There’s a sense in the article that technology becomes a solution to cowardice: “The goal of automated decision-making, they told me is… also to help make the heartbreaking choices of whom among the most exploited and marginalized people in the United States will get help.”
Decision makers are avoiding hard decisions in considering issues like job applications, austerity measures etc.
Rather than dealing with the lack of resources head on, they circumvent dealing with the issue head on in a manner which will actually propogate the issue.</p>
<p>Data scientists can contribute by advocating for “non-technical” forms of knowledge (e.g. from the user-centred research).
Communicating the limits of their work can also help to ensure that data science is used to assist human case workers rather than replace them and/or to simply allocate more resources to the situation, where appropriate.</p>
</section>
<section id="closing-thoughts">
<h2>Closing thoughts<a class="headerlink" href="#closing-thoughts" title="Permalink to this headline">#</a></h2>
<p>We don’t want to make difficult decisions, so it’s easier to pass that decision to an algorithm who can take the blame, but you can’t apply software fixes for hardware problems.
The feeling is that we are generally pessimitic about what you can do to do good with algorithms, although there is potential scope for good.</p>
<p>Making arguments against optimisation wasn’t the point of the article or our discussion - data scientists decide what to optimise for, and in what context.
Is it so bad to optimise things that will help people (such as who is most likely to surive a kidney transplant)?
Algorithms can add value in certain settings and data scientists could help optimise certain outcomes.</p>
<p>But it it can be difficult decide how “deserving” people are of help, and even to decide if “deservingness” is the correct metric to try to use.
If you automate a problem, you often won’t get creative solutions so whilst optimisation is useful, you have to marry it with strong policy proposals.</p>
<p>In order to help, we constantly need to be ethically reviewing our approaches - this can be difficult if you’re the sole data scientist in your context.
Constantly discussing these ideas with peers and colleagues is a great way to get this process of self evaluation going and our best bet to apply algorithms more ethically.
This is the best way to avoid making poorer/marginalised people the “guinea pigs” for the algorithms of the future.</p>
</section>
<section id="voting">
<h2>Voting<a class="headerlink" href="#voting" title="Permalink to this headline">#</a></h2>
<p>Our vote for the next meeting was to discuss:</p>
<p><a class="reference external" href="https://slideslive.com/38923500/critical-perspectives-on-computer-vision">Critical Perspectives on Computer Vision</a> - a ~20 minute video about image recognition/categorisation by Emily Denton, a Senior Research Scientist on Google’s Ethical AI team</p>
<p>and save these two for another time:</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1607.06520.pdf">Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings</a> - paper about how to make word embeddings in language models less biased</p>
<p><a class="reference external" href="https://psyarxiv.com/2mdxh/">A manifesto for big team science</a> - preprint about barriers to doing science as a team (based in psychology)</p>
<p>Our members also said:</p>
<ul class="simple">
<li><p>100% (12 people) that the content this week sparked interesting discussion.</p></li>
<li><p>92% (11 people) said that they’d recommend that others read the content.</p></li>
</ul>
</section>
<section id="contributors">
<h2>Contributors:<a class="headerlink" href="#contributors" title="Permalink to this headline">#</a></h2>
<div class="tip admonition">
<p class="admonition-title">Who contributed?</p>
<p>This is the list of contributors who were comfortable sharing their names publicly.</p>
</div>
<ul class="simple">
<li><p>Natalie Thurlby, Data Scientist, University of Bristol, <a class="reference external" href="https://github.com/NatalieThurlby/">NatalieThurlby</a>, <a class="reference external" href="https://twitter.com/StatalieT">&#64;StatalieT</a>, :sun_with_face:</p></li>
<li><p>Nina Di Cara, PhD Student, University of Bristol, <a class="reference external" href="https://github.com/ninadicara/">ninadicara</a>, <a class="reference external" href="https://twitter.com/ninadicara">&#64;ninadicara</a>, :writing_hand:</p></li>
<li><p>Huw Day, Maths PhDoer, Bristol, <a class="reference external" href="https://twitter.com/disco_huw">&#64;disco_huw</a></p></li>
<li><p>Robin Dasler, data product manager on hiatus, <a class="reference external" href="https://github.com/daslerr">github:daslerr</a></p></li>
<li><p>Paul Lee, investor, &#64;pclee27 www.senseoffairness.blog</p></li>
<li><p>Kamilla Wells, Citizen Developer, Australia <a class="reference external" href="https://www.linkedin.com/in/kamilla-wells/">Kamilla Wells</a></p></li>
<li><p>Miranda Mowbray, honorary lecturer, University of Bristol, mirandamowbray on LinkedIn</p></li>
</ul>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="12-05-21_writeup.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Data Ethics Club discusses Critical perspectives on Computer Vision (12th May 21)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="14-04-21_writeup.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Data Ethics Club discusses: UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape (14th Apr 21)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>

<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      License: <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY-4.0</a>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("G-93XN98JDFL");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>