
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Data Ethics Club: ESR: Ethics and Society Review of Artificial Intelligence Research (8th Sept 21) &#8212; Data Ethics Club v0.1.0 documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Data Ethics Club: “Participant” Perceptions of Twitter Research Ethics (25th Aug 21)" href="25-08-21_writeup.html" />
    <link rel="prev" title="Data Ethics Club: Structural Injustice and Individual Responsibility (6th Oct 2021)" href="06-10-21_writeup.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../../index.html">
<p class="title">Data Ethics Club</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../join_in/join_in.html">
  Join in
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../reading-list.html">
  Reading list
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../write-ups.html">
  Write-ups
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../how_to/reuse_dec.html">
  Reuse our materials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../contact.html">
  Contact us
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../mailing-list.html">
  Mailing list
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/very-good-science/data-ethics-club" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/hashtag/DataEthicsClub" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this site..." aria-label="Search this site..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="03-11-21_writeup.html">
   Data Ethics Club: UK National AI Strategy: Pillar 3 - Governing AI Effectively
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20-10-21_writeup.html">
   Data Ethics Club: Towards decolonising computational sciences (20th Oct 2021)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-10-21_writeup.html">
   Data Ethics Club: Structural Injustice and Individual Responsibility (6th Oct 2021)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Data Ethics Club: ESR: Ethics and Society Review of Artificial Intelligence Research (8th Sept 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="25-08-21_writeup.html">
   Data Ethics Club: “Participant” Perceptions of Twitter Research Ethics (25th Aug 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11-08-21_writeup.html">
   Data Ethics Club: What an ancient lake in Nevada reveals about the future of tech (11th Aug 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="28-07-21_writeup.html">
   Data Ethics Club: The Rise of Private Spies (28th July 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14-07-21_writeup.html">
   Data Ethics Club discusses The mathematics of crime and terrorism (14th July 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="26-05-21_writeup.html">
   Data Ethics Club discusses ‘Living in the Hidden Realms of AI: The Workers Perspective’ (26th May 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12-05-21_writeup.html">
   Data Ethics Club discusses Critical perspectives on Computer Vision (12th May 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="28-04-21_writeup.html">
   Data Ethics Club discusses We created poverty. Algorithms won’t make that go away (28th Apr 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14-04-21_writeup.html">
   Data Ethics Club discusses: UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape (14th Apr 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="31-03-21_writeup.html">
   Data Ethics Club discusses Dataism Is Our New God (31st March 21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17-03-21_writeup.html">
   Data Ethics Club discusses “#bropenscience is broken science” (17th March 21)
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#general-views-about-the-esr-and-how-much-it-adds-to-a-typical-ethical-review-processes-for-ai-research">
   General views about the ESR, and how much it adds to a typical ethical review processes for AI research
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#on-the-consequences-and-moral-character-of-science">
   On the Consequences and Moral Character of Science
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-esr-is-based-around-universities-and-research-funding-would-something-like-this-work-in-other-types-of-organisations-why-why-not">
   The ESR is based around universities and research funding; would something like this work in other types of organisations - why/why not?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attendees">
   Attendees
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="data-ethics-club-esr-ethics-and-society-review-of-artificial-intelligence-research-8th-sept-21">
<h1>Data Ethics Club: <a class="reference external" href="https://arxiv.org/abs/2106.11521">ESR: Ethics and Society Review of Artificial Intelligence Research</a> (8th Sept 21)<a class="headerlink" href="#data-ethics-club-esr-ethics-and-society-review-of-artificial-intelligence-research-8th-sept-21" title="Permalink to this headline">¶</a></h1>
<div class="admonition-what-s-this admonition">
<p class="admonition-title">What’s this? </p>
<p>This is summary of Wednesday 8th September’s Data Ethics Club discussion, where we spoke and wrote about the article <a class="reference external" href="https://arxiv.org/abs/2106.11521">ESR: Ethics and Society Review of Artificial Intelligence Research</a>, written by Michael S. Bernstein, Margaret Levi, David Magnus, Betsy Rajala, Debra Satz and Charla Waeiss.</p>
<p>The summary was written by Huw Day, who tried to synthesise everyone’s contributions to this document and the discussion. “We” = “someone at Data Ethics Club”.
Nina Di Cara and Natalie Thurlby helped with a final edit.</p>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>This week, the group discussed the paper <a class="reference external" href="https://arxiv.org/abs/2106.11521">ESR: Ethics and Society Review of Artificial Intelligence Research</a>, written by Michael S. Bernstein, Margaret Levi, David Magnus, Betsy Rajala, Debra Satz and Charla Waeiss. The abstract of the paper is below:</p>
<p>“Artificial intelligence (AI) research is routinely criticized for its real and potential impacts on society, and we lack adequate institutional responses to this criticism and to the responsibility that it reflects. AI research often falls outside the purview of existing feedback mechanisms such as the Institutional Review Board (IRB), which are designed to evaluate harms to human subjects rather than harms to human society. In response, we have developed the Ethics and Society Review board (ESR), a feedback panel that works with researchers to mitigate negative ethical and societal aspects of AI research. The ESR’s main insight is to serve as a requirement for funding: researchers cannot receive grant funding from a major AI funding program at our university until the researchers complete the ESR process for the proposal. In this article, we describe the ESR as we have designed and run it over its first year across 41 proposals. We analyze aggregate ESR feedback on these proposals, finding that the panel most commonly identifies issues of harms to minority groups, inclusion of diverse stakeholders in the research plan, dual use, and representation in data. Surveys and interviews of researchers who interacted with the ESR found that 58% felt that it had influenced the design of their research project, 100% are willing to continue submitting future projects to the ESR, and that they sought additional scaffolding for reasoning through ethics and society issues.”</p>
<p>With many members of the group having a hand in AI research, it was natural that many of us had opinions on the suggested regulations enforced by the ESR. Most seemed positive on the suggestion of some more appropriate regulations to AI research, but it was difficult to agree on specifics. Since the type of research evolves with the increase in technical capabilities, it is vital that we continue to have these sorts of discussions to continue to maintain strong ethical standards in our research.</p>
</section>
<section id="general-views-about-the-esr-and-how-much-it-adds-to-a-typical-ethical-review-processes-for-ai-research">
<h2>General views about the ESR, and how much it adds to a typical ethical review processes for AI research<a class="headerlink" href="#general-views-about-the-esr-and-how-much-it-adds-to-a-typical-ethical-review-processes-for-ai-research" title="Permalink to this headline">¶</a></h2>
<p>We thought it was a nice idea in theory and that it fills an obvious void in computer science research, (research that doesn’t include humans) in general. Institutional ethical review boards have quite a narrow remit, seeing themselves as protecting research participants. This means they rarely ask questions around the long term ethical implications of research. There is an intersection now for ethical questions about AI and protecting participants and their data, which the methods suggested in this paper would help with.</p>
<p>However we also discussed some critiques of the ESR process:</p>
<ul class="simple">
<li><p>People who could be affected weren’t involved in the decision-making.</p></li>
<li><p>Weakness of review boards in general: lack of transparency. Small number of reviewers. It’s quite hard to envisage the unanticipated stakeholders. Mapping out the conflicts between stakeholders might be useful.</p></li>
<li><p>The paper doesn’t evaluate the process in terms of intended outcome, just on how the participants felt. So perhaps that means we need another review system.</p></li>
<li><p>Would it be necessary to have two separate ethical reviews to go through simultaneously until you satisfy both sets of requirements?</p></li>
<li><p>If ethical review is not enforced across funding groups then researchers might pick and choose funding boards so they have the easiest time hopping through hoops.</p></li>
</ul>
<p>We felt that the paper frames research as a risk, asking researchers to imagine possible negative consequences and seek to mitigate them, but we felt slightly disappointed that it didn’t cover how we do research in the first place.</p>
<p>Asking us, “Under what conditions should we really be doing AI research?”, the paper then leads to a bigger theme: questioning the idea that science is inevtiable and technological progress is inevitable. There is this idea that if we don’t do it, someone else will do. Following this line of thought, perhaps restricting research on ethical grounds will only negatively affect those adhering these ethical standards.</p>
<p>There seems to be this framing by governments who want to use a technological narrative - the idea of technology for the state in order to push for more funding. This paper does challenge this invetiably by saying the review board can say no, but in practice, this was not used much. One case study on AI stress monitoring of employees, the researchers didn’t really respond to any listed concerns.</p>
<p>Agreeing on these sort of things unanimously is impossible, but people trying to remove personal bias is important, i.e. not doing ethical reviews on projects with military funding if you’re unable to be unbiased there. Perhaps we need to start sooner with considering ethical frameworks as early as undergrad research, or at least in PhDs.</p>
</section>
<section id="on-the-consequences-and-moral-character-of-science">
<h2>On the Consequences and Moral Character of Science<a class="headerlink" href="#on-the-consequences-and-moral-character-of-science" title="Permalink to this headline">¶</a></h2>
<p>Consequences of science are very complex and difficult to predict. There is a problem then, with the idea that we can judge science against societal goals. We have very little consensus on this.</p>
<p>One piece of work that touches on this is <a class="reference external" href="https://web.cs.ucdavis.edu/~rogaway/papers/moral-fn.pdf">“The Moral Character of Cryptographic Work”</a> by Philip Rogaway. In it, Rogaway states that “cryptography rearranges power” and so as a result is not only “an inherently political tool”, but it confers “an intrinsically moral dimension” to the field of cryptography. He later goes onto argues that the “inability to effectively address mass surveillance constitutes a failure of our field”. He finishes the abstract with the following sentence: “I plead for a reinvention of our disciplinary culture to attend not only to puzzles and math, but, also, to the societal implications of our work.””</p>
<p>On the contrary, maybe we need to concentrate on the actual crime. <a class="reference external" href="https://en.wikipedia.org/wiki/David_Hilbert">David Hilbert</a> is not at fault for the nuclear bomb even if his mathematical work on Hilbert Spaces helped to make it happen - so far how does the accountability go back?</p>
<p>We should not criminalise behaviours that lead to crimes, we should only criminalise the crimes themselves. Being in poverty and starving might lead to stealing food, but we should not criminalise being in poverty. We should not use laws to control behaviours. Some in the group argued we should approach ethical processes in the same way.</p>
<p>We can’t ask of every scientific advance, “what are the implications?” That’s too complicated. Some in the group argued, instead we should concentrate on making sure society is armed with the tools to control these bad things which will inevitably happening. We can’t control a tech firm using our AI research to be racist. We should not blame ourselves for being curious, we should blame the tech firm for being bad.</p>
<p>Maybe it’s hard to separate the end use with the intention. There exists dual use technology, such as a stress recognition system that may not have solely good intentions. Perhaps you should design it with consideration.</p>
<p>Not to calculate the moral worth of one decision over another, but at least considering intuitive moral decision making around some principles. But what principles? Can we ever agree on them? Academics need to be more humble and a bit more measured in what they say they can do (Ismael Kherroubi Garcia has done <a class="reference external" href="https://towardsdatascience.com/data-science-meaning-and-diversity-bb842602e55d">some excellent writing on this idea</a> in data science, framed as ‘epistemic humility’)</p>
</section>
<section id="the-esr-is-based-around-universities-and-research-funding-would-something-like-this-work-in-other-types-of-organisations-why-why-not">
<h2>The ESR is based around universities and research funding; would something like this work in other types of organisations - why/why not?<a class="headerlink" href="#the-esr-is-based-around-universities-and-research-funding-would-something-like-this-work-in-other-types-of-organisations-why-why-not" title="Permalink to this headline">¶</a></h2>
<p>Stakeholder engagement is always critical and this is not really emphasised in the paper. Second or third-order stakeholders are likely to exist in large-scale businesses, for example:</p>
<ul class="simple">
<li><p>Facebook’s impact on global politics has affected non-users too.</p></li>
<li><p>Deliveroo’s environmental impact is greater if they don’t increase prices for further deliveries.</p></li>
</ul>
<p>Ironically those who hold stakes are not always the stakeholders. Some questions we were left with were:</p>
<ul class="simple">
<li><p>Who are the stakeholders in this ethical review?</p></li>
<li><p>What are the challenges associated with identifying these stakeholders, who they should be and what their different priorities are</p></li>
</ul>
<p>There will be the difficulties of second or third order stakeholders who have nothing to do with the app or whatever but are still impacted by the app itself. For example, Facebook might have affected global politics regardless of whether not you have an account. There will inevitably be a bit of hand wringing about how we could practically apply this, but that does not mean we should ignore the problem entirely.</p>
<p>Is it always a good idea to think about ethics? Probably. Will it be difficult? Almost certainly.</p>
</section>
<hr class="docutils" />
<section id="attendees">
<h2>Attendees<a class="headerlink" href="#attendees" title="Permalink to this headline">¶</a></h2>
<p><strong>Name, Role, Affiliation, Where to find you</strong></p>
<ul class="simple">
<li><p>Natalie Thurlby, Data Scientist, University of Bristol, <a class="reference external" href="https://github.com/NatalieThurlby/">NatalieThurlby</a>, <a class="reference external" href="https://twitter.com/StatalieT">&#64;StatalieT</a></p></li>
<li><p>Huw Day, PhDoer, University of Bristol, <a class="reference external" href="https://twitter.com/disco_huw">&#64;disco_huw</a></p></li>
<li><p>Charlie Newey, Machine Learning Engineer &#64; Deliveroo, <a class="reference external" href="https://github.com/charlienewey">&#64;charlienewey</a>,</p></li>
<li><p>Charles Radclyffe, EthicsGrade</p></li>
</ul>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="06-10-21_writeup.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Data Ethics Club: Structural Injustice and Individual Responsibility (6th Oct 2021)</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="25-08-21_writeup.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Data Ethics Club: “Participant” Perceptions of Twitter Research Ethics (25th Aug 21)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      License: <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY-4.0</a>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.2.<br>
</p>
    </div>
    
  </div>
</footer>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("G-93XN98JDFL");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>