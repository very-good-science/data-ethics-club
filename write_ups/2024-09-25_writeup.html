
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Data Ethics Club: ChatGPT is Bullsh*t &#8212; Data Ethics Club  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=56fe5f99" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'write_ups/2024-09-25_writeup';</script>
    <link rel="canonical" href="dataethicsclub.com/write_ups/2024-09-25_writeup.html" />
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />



  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this site..."
         aria-label="Search this site..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt=""/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">Data Ethics Club</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../join_in/join_in.html">
    ü§ó Join In
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../reading-list.html">
    üìñ Reading List
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="write-ups.html">
    üñäÔ∏è Write-ups
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../how_to/reuse_dec.html">
    ‚ô∫ Reuse
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about/about.html">
    ‚ùì About
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/very-good-science/data-ethics-club" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://www.jiscmail.ac.uk/cgi-bin/webadmin?SUBED1=DATAETHICSCLUB&A=1" title="Mailing List" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-regular fa-envelope fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mailing List</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://doi.org/10.1016/j.patter.2022.100537" title="DEC Paper" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-readme fa-lg" aria-hidden="true"></i>
            <span class="sr-only">DEC Paper</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../join_in/join_in.html">
    ü§ó Join In
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../reading-list.html">
    üìñ Reading List
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="write-ups.html">
    üñäÔ∏è Write-ups
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../how_to/reuse_dec.html">
    ‚ô∫ Reuse
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about/about.html">
    ‚ùì About
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/very-good-science/data-ethics-club" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://www.jiscmail.ac.uk/cgi-bin/webadmin?SUBED1=DATAETHICSCLUB&A=1" title="Mailing List" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-regular fa-envelope fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Mailing List</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://doi.org/10.1016/j.patter.2022.100537" title="DEC Paper" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-readme fa-lg" aria-hidden="true"></i>
            <span class="sr-only">DEC Paper</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__postcard">


<h2>
  
  
  <i class="fa fa-calendar"></i>
  
  <span>25 September 2024</span>
  
</h2>
<ul>
  <div class="ablog-sidebar-item ablog__postcard2">


<li id="ablog-sidebar-item author ablog__author">
  <span>
    
    <i class="fa-fw fa fa-user"></i>
    
    </span>
  
  
  <a href="write-ups/author/jessica-woodgate.html">Jessica Woodgate</a>
  
  
  
</li>




<li id="ablog-sidebar-item category ablog__category">
  <span>
    
    <i class="fa-fw fa fa-folder-open"></i>
    
    </span>
  
  
  <a href="write-ups/category/write-up.html">Write Up</a>
  
  
  
</li>


<li id="ablog-sidebar-item tags ablog__tags">
  <span>
    
    
    <i class="fa-fw fa fa-tags"></i>
    
    
    </span>
  
  
  <a href="write-ups/tag/chatgpt.html">ChatGPT</a>
  
  
  
  
  
  <a href="write-ups/tag/llms.html">LLMs</a>
  
  
  
  
  
  <a href="write-ups/tag/bullshit.html">bullshit</a>
  
  
  
  
  
  <a href="write-ups/tag/hallucination.html">hallucination</a>
  
  
  
</li>


</div>
</ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__recentposts">
<h3>
  <a href="write-ups.html">Recent Posts</a>
</h3>
<ul>
  
  
  <li>
    <a href="2025-03-05_writeup.html">
      05 March - Data Ethics Club: How It‚Äôs Unfair to Use Personality Tests in Hiring (International Women‚Äôs Day Special)
    </a>
  </li>
  
  <li>
    <a href="2025-02-19_writeup.html">
      19 February - Data Ethics Club: OpenAI Furious DeepSeek Might Have Stolen All the Data OpenAI Stole From Us
    </a>
  </li>
  
  <li>
    <a href="2025-02-05_writeup.html">
      05 February - Data Ethics Club: ‚ÄúIt‚Äôs Not Exactly Meant to Be Realistic‚Äù: Student Perspectives on the Role of Ethics In Computing Group Projects
    </a>
  </li>
  
  <li>
    <a href="2025-01-22_writeup.html">
      22 January - Data Ethics Club: Data Ethics New Year‚Äôs Resolutions Special
    </a>
  </li>
  
  <li>
    <a href="2024-12-18_writeup.html">
      18 December - Data Ethics Club: Ask Me Anything! How ChatGPT Got Hyped Into Being
    </a>
  </li>
  
</ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__category">
<h3>
  <a href="write-ups/category.html">Categories</a>
</h3>
<ul>
  
  
  <li>
    <a href="write-ups/category/blog.html">Blog (7)</a>
  </li>
  
  
  
  <li>
    <a href="write-ups/category/bookclub.html">Bookclub (1)</a>
  </li>
  
  
  
  <li>
    <a href="write-ups/category/write-up.html">Write Up (67)</a>
  </li>
  
  
</ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__tags">
<link rel="stylesheet" href="../_static/ablog/tagcloud.css" type="text/css" />
<h3><a href="write-ups/tag.html">Tags</a></h3>
<ul class="ablog-cloud">
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/agi.html">AGI</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/ai-applications.html">AI applications</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/ai-ethics.html">AI ethics</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/ai-in-military.html">AI in military</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/chatgpt.html">ChatGPT</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/fair.html">FAIR</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/khanacademy.html">Khanacademy</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/llms.html">LLMs</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/ml.html">ML</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/new-years-resolutions.html">New Year's Resolutions</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/transparency.html">Transparency</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/ableism.html">ableism</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/abuse.html">abuse</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/art.html">art</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-3">
    <a href="write-ups/tag/automation.html">automation</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-5">
    <a href="write-ups/tag/bias.html">bias</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/big-tech.html">big tech</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/bots.html">bots</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/bullshit.html">bullshit</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/chatbots.html">chatbots</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/children.html">children</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/collective-action.html">collective action</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/communication.html">communication</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/computer-vision.html">computer vision</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/consent.html">consent</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/consumerism.html">consumerism</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/coproduction.html">coproduction</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-2">
    <a href="write-ups/tag/crime.html">crime</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/data-feminism.html">data feminism</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/data-labelling.html">data labelling</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/data-stewardship.html">data stewardship</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/data-week.html">data week</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/dataethics.html">dataethics</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/decolonial-ai.html">decolonial AI</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/decolonisation.html">decolonisation</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/decolonising.html">decolonising</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/deep-fakes.html">deep fakes</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/education.html">education</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/enshittification.html">enshittification</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/environment.html">environment</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/ethics.html">ethics</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/facial-recognition.html">facial recognition</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/fairness.html">fairness</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/feminism.html">feminism</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/gender.html">gender</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/generative-ai.html">generative AI</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-3">
    <a href="write-ups/tag/generativeai.html">generativeAI</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/genetic-testing.html">genetic testing</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/global-south.html">global south</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/google.html">google</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/government-use-of-ai.html">government use of AI</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/group-projects.html">group projects</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/hallucination.html">hallucination</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/healthcare.html">healthcare</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/history.html">history</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/hype.html">hype</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/images-of-ai.html">images of AI</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/injustice.html">injustice</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/interdisciplinary.html">interdisciplinary</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/intersectional-feminism.html">intersectional feminism</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/labour-rights.html">labour rights</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/law.html">law</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/medicine.html">medicine</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/meta-data-ethics.html">meta data ethics</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/metaphor.html">metaphor</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/myers-briggs.html">myers-briggs</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/nlp.html">nlp</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/open-science.html">open science</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/open-source.html">open source</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/outreach.html">outreach</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/oversight.html">oversight</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/personality-test.html">personality test</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/philosophy.html">philosophy</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/policy.html">policy</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/prediction.html">prediction</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-2">
    <a href="write-ups/tag/privacy.html">privacy</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/racism.html">racism</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/recruitment.html">recruitment</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-2">
    <a href="write-ups/tag/research-ethics.html">research ethics</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/resolutions.html">resolutions</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/responsibility.html">responsibility</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/search-engine-optimisation.html">search engine optimisation</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/social.html">social</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/social-media.html">social media</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/sociotechnical-systems.html">sociotechnical systems</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/software-dev.html">software dev</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/standpoint-theory.html">standpoint theory</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/statistics.html">statistics</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/structural-injustice.html">structural injustice</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/trust.html">trust</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/values.html">values</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/war.html">war</a>
  </li>
  
  
  
  <li class="ablog-cloud ablog-cloud-1">
    <a href="write-ups/tag/workers-rights.html">worker's rights</a>
  </li>
  
  
</ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__authors">
<h3><a href="write-ups/author.html">Authors</a></h3>
<ul>
   
  <li>
    <a href="write-ups/author/dwight-barry.html">Dwight Barry (1)</a>
  </li>
    
  <li>
    <a href="write-ups/author/euan-bennet.html">Euan Bennet (1)</a>
  </li>
    
  <li>
    <a href="write-ups/author/hannah-odonoghue.html">Hannah O‚ÄôDonoghue (1)</a>
  </li>
    
  <li>
    <a href="write-ups/author/huw-day.html">Huw Day (34)</a>
  </li>
    
  <li>
    <a href="write-ups/author/jessica-woodgate.html">Jessica Woodgate (33)</a>
  </li>
    
  <li>
    <a href="write-ups/author/natalie-zelenka.html">Natalie Zelenka (3)</a>
  </li>
    
  <li>
    <a href="write-ups/author/nina-di-cara.html">Nina Di Cara (2)</a>
  </li>
    
  <li>
    <a href="write-ups/author/paul-lee.html">Paul Lee (1)</a>
  </li>
    
  <li>
    <a href="write-ups/author/roman-shkunov.html">Roman Shkunov (1)</a>
  </li>
    
  <li>
    <a href="write-ups/author/vanessa-hanschke.html">Vanessa Hanschke (1)</a>
  </li>
   
</ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__archive">
<h3>
  <a href="write-ups/archive.html">Archives</a>
</h3>
<ul>
  
  
  <li>
    <a href="write-ups/2025.html">2025 (4)</a>
  </li>
  
  
  
  <li>
    <a href="write-ups/2024.html">2024 (20)</a>
  </li>
  
  
  
  <li>
    <a href="write-ups/2023.html">2023 (15)</a>
  </li>
  
  
  
  <li>
    <a href="write-ups/2022.html">2022 (20)</a>
  </li>
  
  
  
  <li>
    <a href="write-ups/2021.html">2021 (16)</a>
  </li>
  
  
</ul>
</div>
</div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Data Ethics Club: ChatGPT is Bullsh*t</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
<section id="data-ethics-club-chatgpt-is-bullsh-t">
<h1>Data Ethics Club: <a class="reference external" href="https://link.springer.com/article/10.1007/s10676-024-09775-5">ChatGPT is Bullsh*t</a><a class="headerlink" href="#data-ethics-club-chatgpt-is-bullsh-t" title="Link to this heading">#</a></h1>
<div class="admonition-what-s-this admonition">
<p class="admonition-title">What‚Äôs this?</p>
<p>This is summary of Wednesday 25th September‚Äôs Data Ethics Club discussion, where we spoke and wrote about the article <a class="reference external" href="https://link.springer.com/article/10.1007/s10676-024-09775-5">ChatGPT is Bullsh*t</a>.
The summary was written by Jessica Woodgate, who tried to synthesise everyone‚Äôs contributions to this document and the discussion. ‚ÄúWe‚Äù = ‚Äúsomeone at Data Ethics Club‚Äù.
Huw Day helped with the final edit.</p>
</div>
<section id="article-summary">
<h2>Article Summary<a class="headerlink" href="#article-summary" title="Link to this heading">#</a></h2>
<p>Tackling the problem of large language models (LLMs) outputting false statements is an increasingly important problem as LLMs are employed across more areas of society. Falsities generated by LLMs are commonly referred to as ‚Äòhallucinations‚Äô. This paper argues that hallucination ‚Äúis an inapt metaphor which will misinform the public, policymakers, and other interested parties‚Äù. To better address the topic, the paper suggests that the label ‚Äòbullshit‚Äô is more appropriate than hallucinate, as LLMs are designed to give the impression that they are accurately representing the world. The paper distinguishes between ‚Äòhard‚Äô bullshit, requiring an active attempt to deceive the audience, and ‚Äòsoft‚Äô bullshit, requiring a lack of concern for the truth. LLMs outputs are framed as soft bullshit at a minimum, and hard bullshit if we view LLMs as having intentions, for example, in virtue of how they are designed.</p>
</section>
<section id="discussion-summary">
<h2>Discussion Summary<a class="headerlink" href="#discussion-summary" title="Link to this heading">#</a></h2>
<section id="do-you-think-that-the-labels-of-chatgpt-as-a-bullshit-machine-is-fair">
<h3>Do you think that the labels of ChatGPT as a bullshit machine is fair?<a class="headerlink" href="#do-you-think-that-the-labels-of-chatgpt-as-a-bullshit-machine-is-fair" title="Link to this heading">#</a></h3>
<p>Giving LLMs like ChatGPT labels is a path to improve understanding about the mechanics of how the tools work. Understanding mechanics and defining the (limits of) LLM capabilities is important to reduce harms and ensure they are used correctly. Users need to understand how models are designed in order to evaluate the output. Intentional metaphors can be helpful in conveying what a system is designed to do. However, if used inappropriately, metaphors can be misleading. For instance, the ‚Äòlearning‚Äô part of ‚Äòmachine learning‚Äô is actually something that looks more like recombining. Examples of the kinds of problems that can arise from misconceptions about the capabilities of AI can be seen in domains like digital health. In digital health, we are finding that people look to ChatGPT to diagnose problems <a class="reference external" href="https://theconversation.com/how-good-is-chatgpt-at-diagnosing-disease-a-doctor-puts-it-through-its-paces-203281">which it is not yet capable of doing reliably</a>.</p>
<p>To encapsulate what is really going on when an LLM is prompted, it is important to understand the ‚Äòtemperature‚Äô parameter, of which the paper provides a good explanation. The temperature parameter <a class="reference external" href="https://medium.com/&#64;albert_88839/large-language-model-settings-temperature-top-p-and-max-tokens-1a0b54dcb25e">‚Äúdefines the randomness of LLM response. The higher the temperature, the more diverse and creative the output‚Äù</a>. In other words, temperature enables the model to be tuned to choose more randomly amongst likely words, rather than choosing the most likely word. The effect of this, the paper conveys, is more ‚Äúcreative and human-like text‚Äù as well as a higher likelihood of falsehoods.</p>
<p>In framing the effects of elements like temperature, the label ‚Äòbullshit‚Äô does seem appropriate. The paper argues that the temperature parameter shows that the goal of LLMs is not to convey helpful information, but ‚Äúto provide a normal-seeming response to a prompt‚Äù. LLMs are designed to ‚Äúgive the impression‚Äù that the answer is accurate, rather than giving an accurate answer. Bullshit, understood as an indifference to the truth, encapsulates the way that LLMs are designed to prioritise objectives. Whilst bullshit might seem a bit clickbait-y, it is effective at drawing you in. Some of us experienced confirmation bias just looking at the title, feeling that it puts into words how we feel about the topic.</p>
<p>For those of us that are more sceptical of ChatGPT, rather than seeing it as right or wrong, we thought that the paper presents a useful paradigm within which to frame a conversation. Paradigm discussions in data science are really important, such as <a class="reference external" href="https://www.datacamp.com/blog/the-difference-between-ai-and-machine-learning">machine learning vs. AI paradigms</a>. In discussing paradigms, analytical philosophy surrounding language and precise definitions facilitates scoping areas and highlighting misconceptions. It is fun to utilise a well-defined but playful word like bullshit in this analysis.</p>
<p>The crux of the paper contrasts bullshit with the term currently used when LLMs output false information ‚Äì ‚Äòhallucinate‚Äô. Hallucinate seems to be a term which has entered common language by slowly creeping in, rather than through the careful and thought-out selection of words that we see in philosophy. We wondered why it has been used as phrasing in the first place. One idea the term hallucinate may be appropriate comes from the fact that in humans, hallucinations can have an element of truth in the individual‚Äôs life. This could mirror how in LLMs, the ‚Äòrandom‚Äô output has some root in its training data.</p>
<p>Despite some elements of ‚Äòhallucinate‚Äô that fit with what LLMs do, it doesn‚Äôt quite capture the meaning. Hallucinate has misleading elements, such as the implication that it is something that ‚Äòjust happens‚Äô. Human hallucinations are without intention; bullshit is a term that is less neutral and encompasses the effect of intention. Intention includes both the output of the system itself, and the work that goes into building the systems. Saying that a system is hallucinating insinuates that its output is not the designers‚Äô fault. Hallucinate thus propagates a false narrative that distances the system designers from the system‚Äôs output, thereby side-stepping accountability.</p>
<p>The false narrative around AI glosses over the human input in these systems, masking the role of intention by presenting a fa√ßade that no humans are involved. In reality, there is <a class="reference external" href="https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots">a lot of human work that goes into AI</a> (as discussed in a <a class="reference external" href="https://dataethicsclub.com/write_ups/2024-05-08_writeup.html">previous Data Ethics Club</a>). Users are duped into thinking that the technology works much better than it really does.</p>
<p>Labelling LLM outputs as bullshit is supported by the notion that common use cases for LLMs are areas where people already bullshit. We see LLMs used in everyday practices where convincingness is prioritised above accuracy, like in emails, marketing, and research proposals. There was the <a class="reference external" href="https://www.legaldive.com/news/chatgpt-fake-legal-cases-generative-ai-hallucinations/651557/">lawyer that used fake cases generated by ChatGPT in his brief</a>. We also saw fraud and liability as massive use cases for LLMs and wondered if there is any responsibility for those who break the law by using LLMs in these ways.</p>
<p>Bullshit helps to tie the output and effects of LLMs to their human designers, highlighting the human responsibility in the creation of LLMs. Giving the interface of LLMs agency distracts from the designers involved in the system, and their bias. Using the label bullshit helps to reforge this connection to intention and responsibility, thereby improving awareness about underlying mechanics.</p>
<p>Whilst we saw more strengths to the label ‚Äòbullshit‚Äô than ‚Äòhallucinate‚Äô, there are some aspects of ‚Äòbullshit‚Äô that we had difficulty with. It is not an easy word to use generically and has various connotations which need qualification. ‚ÄòBullshit‚Äô as a term is intended for people and seems a bit anthropomorphic, even with the disclaimers in the paper. ‚ÄòBullshit machine‚Äô could be better, or perhaps ‚Äòbullshit facilitator‚Äô. We also considered the term <a class="reference external" href="https://en.wikipedia.org/wiki/Confabulation">‚Äòconfabulation‚Äô</a>, which is ‚Äúa memory error consisting of the production of fabricated, distorted, or misinterpreted memories about oneself or the world‚Äù.</p>
<p>Although ChatGPT does have a tendency to spit out falsehoods, it might be unfair to call it a bullshit machine if 90% of the output is true. If it is just a predictive tool, which usually predicts correctly, it‚Äôs output might not necessarily be classed as bullshit. We expect much more from machines than humans; as humans, we can go our entire lives believing statements to be true and telling other people those statements are true, to find out one day we are wrong. If someone bullshits us, and we believe it to be true and share it with others, we wouldn‚Äôt consider ourselves to be bullshitters.</p>
</section>
<section id="do-you-think-chatgpt-is-a-soft-or-a-hard-bullshitter-i-e-do-you-think-it-has-the-intention-to-mislead-its-audience-or-not">
<h3>Do you think ChatGPT is a soft or a hard bullshitter? I.e. do you think it has the intention to mislead its audience or not?<a class="headerlink" href="#do-you-think-chatgpt-is-a-soft-or-a-hard-bullshitter-i-e-do-you-think-it-has-the-intention-to-mislead-its-audience-or-not" title="Link to this heading">#</a></h3>
<p>We liked the clear distinction between soft and hard bullshitting, where a soft bullshitter need not have an intention to mislead, but a hard bullshitter does. We would welcome more of a distinction between a hard bullshitter and a liar. Hard bullshitting might be prevented from collapsing into lying if there are underlying ulterior motives.</p>
<p>Whether ChatGPT is soft or hard could depend on its version, with a difference in labels between earlier and later versions. Pre-reinforcement learning (RL), there was less effort dedicated to making sure that ChatGPT was not misleading people. The use of human assisted RL (e.g. <a class="reference external" href="https://huggingface.co/blog/rlhf">RL from human feedback</a>) seems to play an important part in distinguishing between soft and hard bullshit.</p>
<p>On one hand, using human assisted RL might make ChatGPT a soft bullshitter, because an effort (no matter how small) has been made to not mislead. Framing ChatGPT as a soft bullshitter could also be supported by the disclaimer on the bottom, alerting people that it might offer false information. If ChatGPT is devoid of intention, or the output isn‚Äôt presented as truth or knowledge, it could be labelled soft bullshit. However, hard vs. soft bullshit makes it seem like hard is worse; it should be made clear that soft is still bad and can be very disruptive. For example, if it is soft, we might care less about verifying it, whereas we would try to fix it from being wrong if it was hard.</p>
<p>On the other hand, the use of human assisted RL may contribute to producing something closer to hard bullshit, as there is a transition from repeating probable words towards being ‚Äòconvincing‚Äô. RL is used to both make the output more truthful and also to look more ‚Äòtruthy‚Äô. If we only care about intention in distinguishing between hard and soft bullshit, doing RL changes the appropriate label as it changes the role of intention. Knowing ‚Äòtrue‚Äô vs. ‚Äòfalse‚Äô is not enough information to learn to give better answers, and designers will have to make some choices in what defines a better answer. The choices that need to be made when involving RL could be interpreted as the intention of the designers. When intention is involved, ChatGPT thus enters into the space of hard bullshit where the model is trying to convince.</p>
<p>Intention may be of the system‚Äôs creators, or of the system itself. The idea of system itself having intention is supported by the importance of process. In the same way that students should learn from the process of writing, it is the practice that is important, not how polished the end result is. This means that no matter how frequently ChatGPT is accurate, it may still be a bullshit machine if it doesn‚Äôt go through the right process. For example, not telling the user how sure it is of its answer may increase the system‚Äôs level of accountability. The significance of process is why the <a class="reference external" href="https://www.theverge.com/2024/8/2/24212078/google-gemini-olympics-ad-backlash">controversial ad for Gemini got pulled</a>, in which a father used the tool to write an athlete a fan letter on behalf of his daughter. The advert arguably encourages ‚Äútaking the easy way out instead of practicing self-expression‚Äù.</p>
<p>We found that the paper seemed to jump around a bit regarding who was being accused of bullshitting; whether it was the users, the creators, or something else. There also seems to be a scale of intentionality in bullshitting, from students avoiding doing their work, to politicians misleading the public. Downstream, it is difficult to delineate responsibility for the use of the system between the users and the designers. For intentionality in LLMs, we wondered <a class="reference external" href="https://link.springer.com/article/10.1007/s43681-022-00256-3">how far developers have ethical agency, and where the buck stops</a>. The people who develop LLMs do not intend to mislead audiences, they intend to develop useful tools.</p>
<p>However, commercialising and selling tools for specific unfit purposes could be classed as intentionally misleading. Designing bots to exhibit human-like qualities has some intention to deceive. The intent of the dataset an LLM was trained on is also important, for example, whether it is academic articles, or articles from tabloid newspapers. The information it was trained on would steer the intent; this would be the intent of the designers and sources, not the LLM. A lack of availability of underlying sources contributes to the bullshit factor.</p>
<p>The existence of intention to mislead likely results from the <a class="reference external" href="https://link.springer.com/article/10.1007/s43681-024-00458-x">industry fixation on innovation. The obsession with innovation amongst other factors, has been found to be a significant barrier inhibiting ethical wisdom in the AI developer community</a>. There is always a human at the top of the chain who is pulling the AI along; if we are looking to hold someone responsible, you just have to follow that chain.</p>
<p>Even when the intention to mislead is absent, knowing how to train LLMs to portray truth is complicated by the fact that the concept of truth is a philosophical minefield. If it was easy to define truth, we wouldn‚Äôt have a justice system or journalists. There are situations where we presume the truth is knowable, and situations where we presume truth is unknowable. When an LLM hallucinates, compared to when it tells the truth, it feels like something procedurally different is happening, but really it is exactly the same process.</p>
<p>The authors are correct to point out that the relationship to the truth is irrelevant to LLMs. LLMs aren‚Äôt tracking ‚Äòtruth‚Äô as they have no commitment or connection to the whole picture. Whether LLM outputs are true or false, the intent is always the same. With the variation in temperature parameter, we know that they frequently don‚Äôt give us the best guess, trading off accuracy with authenticity. This trade-off produces speech which looks human but is indifferent to the truth. Even with zero temperature, LLMs won‚Äôt make stuff up but just go with the consensus of text they are trained on. Going with the consensus seems to align more with parroting than tracking truth.</p>
<p>Considering the difficulties with assigning intentionality, accountability, and defining truth, we wondered if the distinction between hard and soft bullshit is persistently useful. It is difficult to quantify each term, and you can‚Äôt extend either definition to all applications of LLMs. Assigning labels to the system themselves is compounded by irresponsible use of LLMs. Once you‚Äôve decided that LLMs are hard bullshitters, we wondered if they could become soft bullshitters, e.g. by learning, or labelling their own uncertainties with data. Accuracy can be a training goal.</p>
</section>
<section id="what-do-you-think-of-the-implications-of-the-anthropomorphising-of-ai-tools-e-g-hallucination-learning-training-perception-etc">
<h3>What do you think of the implications of the anthropomorphising of AI tools? E.g. hallucination, learning, training, perception etc.<a class="headerlink" href="#what-do-you-think-of-the-implications-of-the-anthropomorphising-of-ai-tools-e-g-hallucination-learning-training-perception-etc" title="Link to this heading">#</a></h3>
<p>To truly answer any of the questions we have discussed above, we must address anthropomorphism. As humans, we have a natural tendency to anthropomorphise; we can‚Äôt get away from our own human experience, conceptualising the world by reference to ourselves. We wondered if over-anthropomorphism is inherent across humanity, or if it is something seen especially in Anglican traditions. We see anthropomorphism in many systems other than LLMs, such as in robotics. In the Robotics Process Automation office, workers will name their software bot (e.g. Bobby Bot) and talk about the bot as if it is a colleague, for example saying ‚ÄúBobby‚Äôs having a bad day today‚Äù when describing lots of exceptions.</p>
<p>Anthropomorphism risks prescribing more intentionality than we mean to, similar to the effects of <a class="reference external" href="https://en.wikipedia.org/wiki/Pareidolia">pareidolia</a>, which is the tendency for perception to ‚Äúimpose a meaningful interpretation on nebulous stimulus‚Äù. We had some doubts about as to whether it is possible to ascribe intention to mislead to LLMs themselves, as this may be a case of anthropomorphism.</p>
<p>The problem with anthropomorphism is that it does a disservice to how the system works, which affects broad fields (e.g. science) by trivialising and bypassing the underlying mechanics. As well as disguising technical aspects, anthropomorphism has social repercussions. People respond well to human projections on non-human items, and can build human-like relationships with them, finding friendship and companionship (this is explored in a <a class="reference external" href="https://dataethicsclub.com/write_ups/2024-02-14_writeup.html">previous Data Ethics Club</a>, the podcast <a class="reference external" href="https://www.theguardian.com/technology/series/blackbox">Black Box</a>, and TV show <a class="reference external" href="https://www.imdb.com/title/tt4122068/">Humans</a>).</p>
<p>To some extent, the dynamics of LLMs as bullshit machines are not so different to human relationships ‚Äì we all have friends who are bullshitters and can navigate LLMs in similar ways to how we navigate these friendships. However, the similarity to human relationships poses a risk to people that are vulnerable and can induce trust where it might not be deserved. When we consider the technology in isolation, it is weird to think about whether or not we can trust it. However, when the tools are anthropomorphised, trusting them becomes a natural consequence. When that trust is proven misplaced, such as ChatGPT outputting falsehoods, trust in written language is lost, and people start to consume text differently.</p>
</section>
<section id="what-change-would-you-like-to-see-on-the-basis-of-this-piece-who-has-the-power-to-make-that-change">
<h3>What change would you like to see on the basis of this piece? Who has the power to make that change?<a class="headerlink" href="#what-change-would-you-like-to-see-on-the-basis-of-this-piece-who-has-the-power-to-make-that-change" title="Link to this heading">#</a></h3>
<p>If the technology will increase efficiency and save lives, then there are strong arguments in favour of using it. However, at the moment there are a range of responses to good and bad practice of AI in research and education. These responses need to be streamlined to orient AI development with society. We know how to deal with cats, but not lions; we should not release lions into the city without knowing who or how to control it.</p>
<p>We thought that the paper is kind of missing the ‚Äòso what?‚Äô element at the end, without showing the dangers of the technology. Lying is already a part of our society ‚Äì why is ChatGPT different?</p>
<p>One reason ChatGPT is different is because of the scope of its repercussions; we have seen that the repercussions are large and affect many domains. For example, search engines appear to be devolving as the internet is gradually filled with generated content, <a class="reference external" href="https://dataethicsclub.com/write_ups/2024-02-28_writeup.html">discussed in a previous Data Ethics Club</a>. Another destructive repercussion of LLMs is <a class="reference external" href="https://medium.com/darrowai/code-green-addressing-the-environmental-impact-of-language-models-0161eb790c21">their environmental impact</a>. The Washington Post estimates that to construct <a class="reference external" href="https://www.washingtonpost.com/technology/2024/09/18/energy-ai-use-electricity-water-data-centers/">one 100-word email, about a bottle of water, or enough electricity to power 14 LED light bulbs for an hour is used; for 1 out of 10 working Americans to construct one email once a week, the amount of water consumed by all Rhode Island households for 1.5 days or the electricity consumed by all D.C. households for 20 days is used</a>. There could be creative solutions to the environmental effects of AI, such as the <a class="reference external" href="https://www.bbc.com/news/technology-64939558">data centre in Devon which is uses the heat it generates to warm a public swimming pool</a>.</p>
<p>To move forwards with technologies like ChatGPT, we thus need to be clear about how we are using them and what we are using them for. Many of us feel that LLMs are useful tools ‚Äì there are cases of <a class="reference external" href="https://mathstodon.xyz/&#64;tao/110601051375142142">LLMs doing maths to a grad student level of proficiency</a> - and just want to clarify when they are useful. Whatever your opinion about them, LLMs are going to be used, so we need to decide when we can rely on them and what the good use cases are.</p>
<p>Correct language plays an important role in clarifying the usefulness of LLMs. Applying the label of bullshit machine to LLMs can inform how you use them, as you enter into interactions with the expectation that a lot of it might be bullshit. LLMs tell us things, and we should verify that the outputs are true, under the assumption that they are not. Only when we have verified the facts should we share them. There are tools you can buy to check literature and understand which parts of a textual artefact are true, e.g. <a class="reference external" href="https://www.wolframalpha.com">Wolfram Alpha</a> can be used as a truth checker.</p>
<p>Contemplating what might come in the future, and how to reduce harm, is informed by looking to scenarios where similar concerns have arisen before. Where we are now with ChatGPT could be paralleled with <a class="reference external" href="https://en.wikipedia.org/wiki/Criticism_of_Wikipedia">worries that people had about Wikipedia when it started</a>. The fears about Wikipedia were largely overblown, and perhaps this will also be true regarding the fears surrounding ChatGPT. In the future, ChatGPT could be used as a conversation starter, but not as the ‚Äòmain thing‚Äô. However, the key factor that differentiates the two is that Wikipedia has citations, making the sources evident. To circumvent this gap with ChatGPT, aside from including the actual citations, LLMs could include ‚Äòconfidence ratings‚Äô on the statements they‚Äôre generating, based on the probabilities of the words being strung together.</p>
</section>
</section>
<section id="attendees">
<h2>Attendees<a class="headerlink" href="#attendees" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Huw Day, Data Scientist, Jean Golding Institute, University of Bristol, https://www.linkedin.com/in/huw-day/</p></li>
<li><p>Amy Joint, Programme Manager, ISRCTN clinical study registry</p></li>
<li><p>Vanessa Hanschke, PhD Interactive AI, University of Bristol</p></li>
<li><p>Zo√´ Turner, Senior Data Scientist, The Strategy Unit (NHS)</p></li>
<li><p>Paul Matthews, Senior Lecturer, UWE Bristol, https://scholar.social/&#64;paulusm</p></li>
<li><p>Virginia Scarlett, Data and Information Specialist, HHMI Janelia :grimacing:</p></li>
<li><p>Joe Slater, Philosophy, University of Glasgow Philosophy Department.</p></li>
<li><p>Chris Jones, Data Scientist</p></li>
<li><p>Joe Carver, Data Scientist, Brandwatch</p></li>
<li><p>Dani Shanley, Philosophy, Maastricht University</p></li>
<li><p>Mike Hicks, Philosophy, University of Glasgow</p></li>
<li><p><a class="reference external" href="https://www.linkedin.com/in/kamilla-wells/">Kamilla Wells</a>, Citizen Developer, Australian Public Service, Brisbane</p></li>
<li><p>Euan Bennet, Lecturer, University of Glasgow</p></li>
<li><p><a class="reference external" href="https://www.linkedin.com/in/robindasler">Robin Dasler</a>, data product manager, California</p></li>
<li><p>Helen Sheehan, PhD Student, University of Bristol</p></li>
<li><p>Matimba Swana, PhD Student, University of Bristol</p></li>
<li><p><a class="reference external" href="https://www.linkedin.com/in/danrsl/">Dan Levy</a>, Data Analyst, BNSSG ICB (NHS, Bristol)</p></li>
</ul>
</section>
</section>

<div class="section ablog__blog_comments">
  
  


<div class="section ablog__prev-next">
  <span class="ablog__prev">
    
    
    <a href="2024-08-31_writeup.html">
      
      <i class="fa fa-arrow-circle-left"></i>
      
      <span>Data Ethics Club reads ‚ÄúData Feminism‚Äù: Summer Bookclub 2024</span>
    </a>
    
  </span>
  <span class="ablog__spacer">&nbsp;</span>
  <span class="ablog__next">
    
    
    <a href="2024-10-09_writeup.html">
      <span>Data Ethics Club: Time to reality check the promises of machine learning-powered precision medicine</span>
      
      <i class="fa fa-arrow-circle-right" ></i>
      
    </a>
    
  </span>
</div>

  
  
</div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#article-summary">Article Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion-summary">Discussion Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#do-you-think-that-the-labels-of-chatgpt-as-a-bullshit-machine-is-fair">Do you think that the labels of ChatGPT as a bullshit machine is fair?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#do-you-think-chatgpt-is-a-soft-or-a-hard-bullshitter-i-e-do-you-think-it-has-the-intention-to-mislead-its-audience-or-not">Do you think ChatGPT is a soft or a hard bullshitter? I.e. do you think it has the intention to mislead its audience or not?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-do-you-think-of-the-implications-of-the-anthropomorphising-of-ai-tools-e-g-hallucination-learning-training-perception-etc">What do you think of the implications of the anthropomorphising of AI tools? E.g. hallucination, learning, training, perception etc.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-change-would-you-like-to-see-on-the-basis-of-this-piece-who-has-the-power-to-make-that-change">What change would you like to see on the basis of this piece? Who has the power to make that change?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#attendees">Attendees</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/very-good-science/data-ethics-club/edit/main//site/write_ups/2024-09-25_writeup.md">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/write_ups/2024-09-25_writeup.md.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>


  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2024, Data Ethics Club Community.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("G-93XN98JDFL");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>