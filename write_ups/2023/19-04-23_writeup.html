

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Data Ethics Club: Social Biases in NLP Models as Barriers for Persons with Disabilities &#8212; Data Ethics Club v0.1.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'write_ups/2023/19-04-23_writeup';</script>
    <link rel="canonical" href="dataethicsclub.com/write_ups/2023/19-04-23_writeup.html" />
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Data Ethics Club: The Tech We Won’t Build" href="29-03-23_writeup.html" />
    <link rel="prev" title="Data Ethics Club: Queer In AI: A Case Study in Community-Led Participatory AI" href="03-05-23_writeup.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this site..."
         aria-label="Search this site..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">Data Ethics Club v0.1.0 documentation</p>
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../join_in/join_in.html">
                        Join in
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reading-list.html">
                        Reading list
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../write-ups.html">
                        Write-ups
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../how_to/reuse_dec.html">
                        Reuse our materials
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../contact.html">
                        Contact us
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mailing-list.html">
                        Mailing list
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/very-good-science/data-ethics-club" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/hashtag/DataEthicsClub" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../join_in/join_in.html">
                        Join in
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reading-list.html">
                        Reading list
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../write-ups.html">
                        Write-ups
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../how_to/reuse_dec.html">
                        Reuse our materials
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../contact.html">
                        Contact us
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mailing-list.html">
                        Mailing list
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/very-good-science/data-ethics-club" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/hashtag/DataEthicsClub" title="Twitter" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-twitter"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="05-06-23_writeup.html">Data Ethics Club Data Week 2023 Special: The Real Danger of ChatGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="31-05-23_writeup.html">Data Ethics Club: Owen Jones on the classification of abuse online</a></li>
<li class="toctree-l1"><a class="reference internal" href="17-05-23_writeup.html">Data Ethics Club: Designing Accountable Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-05-23_writeup.html">Data Ethics Club: Queer In AI: A Case Study in Community-Led Participatory AI</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Data Ethics Club: Social Biases in NLP Models as Barriers for Persons with Disabilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="29-03-23_writeup.html">Data Ethics Club: The Tech We Won’t Build</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-03-23_writeup.html">Data Ethics Club: Limits and Possibilities for “Ethical AI” in Open Source: A Study of Deepfakes</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-02-23_writeup.html">Data Ethics Club: ChatGPT listed as an author on research papers: many scientists disapprove</a></li>
<li class="toctree-l1"><a class="reference internal" href="25-01-23_writeup.html">Data Ethics Club: Data Ethics Resolutions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/ChatGPTStoleMyJob.html">Chat GPT Stole my Job</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/14-12-22_writeup.html">Data Ethics Club: Defective Altruism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/FAIRBlog.html">But is it FAIR?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/16-11-22_writeup.html">Data Ethics Club: The Ethics of AI generated art</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/02-11-22_writeup.html">Data Ethics Club: ‘The data was there – so why did it take coronavirus to wake us up to racial health inequalities?’</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/19-10-22_writeup.html">Data Ethics Club: Patient and public involvement to build trust in artificial intelligence: A framework, tools, and case studies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/05-10-22_writeup.html">Data Ethics Club: The Failures of Algorithmic Fairness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/21-09-22_writeup.html">Data Ethics Club: Hacking the cis-tem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/MarginalisedGroups.html">Garbage in, garbage out: How bad use of data harms marginalised groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/MetaphorsBlogPost.html">Cleaning the oil spill of data metaphors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/GLMBlogpost.html">The G in GLMs sometimes stands for “Garbage” – what I learnt getting students to design algorithms for hiring and firing teachers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/16-06-22_writeup.html">Data Ethics Club: Automating Inequality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/01-06-22_writeup.html">Data Ethics Club: Participatory Data Stewardship</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/18-05-22_writeup.html">Data Ethics Club: Why data is never raw</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/04-05-22_writeup.html">Data Ethics Club: Economies of Virtue: The Circulation of ‘Ethics’ in Big Tech</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/06-04-22_writeup.html">Data Ethics Club: The Algorithmic Colonization of Africa</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/23-03-22_writeup.html">Data Ethics Club: The Tyranny of Structurelessness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/09-03-22_writeup.html">Data Ethics Club: AI in Warfare</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/09-02-22_writeup.html">Data Ethics Club: “You Social Scientists Love Mind Games”: Experimenting in the “divide” between data science and critical algorithm studies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/26-01-22_writeup.html">Data Ethics Club: Which Programming Languages Use the Least Electricity?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2022/12-01-22_writeup.html">Data Ethics Club: Resolutions 2022</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/15-12-21_writeup.html">Data Ethics Club: A Question of Trust</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/17-11-21_writeup.html">Data Ethics Club: Statistics, Eugenics and Me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/03-11-21_writeup.html">Data Ethics Club: UK National AI Strategy: Pillar 3 - Governing AI Effectively</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/20-10-21_writeup.html">Data Ethics Club: Towards decolonising computational sciences (20th Oct 2021)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/06-10-21_writeup.html">Data Ethics Club: Structural Injustice and Individual Responsibility (6th Oct 2021)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/08-09-21_writeup.html">Data Ethics Club: ESR: Ethics and Society Review of Artificial Intelligence Research (8th Sept 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/25-08-21_writeup.html">Data Ethics Club: “Participant” Perceptions of Twitter Research Ethics (25th Aug 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/11-08-21_writeup.html">Data Ethics Club: What an ancient lake in Nevada reveals about the future of tech (11th Aug 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/28-07-21_writeup.html">Data Ethics Club: The Rise of Private Spies (28th July 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/14-07-21_writeup.html">Data Ethics Club discusses The mathematics of crime and terrorism (14th July 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/26-05-21_writeup.html">Data Ethics Club discusses ‘Living in the Hidden Realms of AI: The Workers Perspective’ (26th May 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/12-05-21_writeup.html">Data Ethics Club discusses Critical perspectives on Computer Vision (12th May 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/28-04-21_writeup.html">Data Ethics Club discusses We created poverty. Algorithms won’t make that go away (28th Apr 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/14-04-21_writeup.html">Data Ethics Club discusses: UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape (14th Apr 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/31-03-21_writeup.html">Data Ethics Club discusses Dataism Is Our New God (31st March 21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../2021/17-03-21_writeup.html">Data Ethics Club discusses “#bropenscience is broken science” (17th March 21)</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../write-ups.html" class="nav-link">Write-ups</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Data Ethics Club: Social Biases in NLP Models as Barriers for Persons with Disabilities</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="data-ethics-club-social-biases-in-nlp-models-as-barriers-for-persons-with-disabilities">
<h1>Data Ethics Club: <a class="reference external" href="https://arxiv.org/pdf/2005.00813.pdf">Social Biases in NLP Models as Barriers for Persons with Disabilities</a><a class="headerlink" href="#data-ethics-club-social-biases-in-nlp-models-as-barriers-for-persons-with-disabilities" title="Permalink to this headline">#</a></h1>
<div class="admonition-what-s-this admonition">
<p class="admonition-title">What’s this? </p>
<p>This is summary of Wednesday 19th April’s Data Ethics Club discussion, where we spoke and wrote about <a class="reference external" href="https://arxiv.org/pdf/2005.00813.pdf">Social Biases in NLP Models as Barriers for Persons with Disabilities</a>, a paper written by Ben Hutchinson, Vinodkumar Prabhakaran, Emily Denton, Kellie Webster, Yu Zhong, Stephen Denuyl.
The summary was written by Huw Day and Jessica Woodgate, who tried to synthesise everyone’s contributions to this document and the discussion. “We” = “someone at Data Ethics Club”.
Nina Di Cara and Natalie Thurlby helped with the final edit.</p>
</div>
<section id="discussion">
<h2>Discussion<a class="headerlink" href="#discussion" title="Permalink to this headline">#</a></h2>
<section id="opening-thoughts">
<h3>Opening thoughts<a class="headerlink" href="#opening-thoughts" title="Permalink to this headline">#</a></h3>
<p>A lot of us did not enjoy this paper and were skeptical about aspects of it, particuarly those on sentiment analysis. We did however enjoy the discussion after the fact.</p>
<p>We wondered how do you define disability? How do you define conversations around different physical disabilities? Who makes these</p>
<p>The databases that the model in the paper is trained on are guidelines published by three US-based organizations: <a class="reference external" href="https://www.adl.org/">Anti-Defamation League</a>, <a class="reference external" href="https://www.sigaccess.org/welcome-to-sigaccess/resources/">SIGACCESS</a> and the <a class="reference external" href="https://adata.org/">ADA National Network</a>.</p>
<p>How up to date are these guidelines? What bias is encoded there? What’s the half life of this kind of dataset? Would you need to update this every couple of years as language evolves?</p>
<p>We also didn’t like that there were no mention of mitigation methods.</p>
<p>In a meeting on the famous <a class="reference external" href="https://dl.acm.org/doi/10.1145/3442188.3445922">Stochastic parrots paper</a>, a worker from Kenya talked about their experience assisting training for <a class="reference external" href="https://dataethicsclub.com/write_ups/2023/07-02-23_writeup.html">ChatGPT</a>. Workers aimed to make ChatGPT  less toxic by getting moderators to score sentences on toxicity - the rationale was that if ChatGPT gets an insight into what constitutes as toxic, it can aim to produce less content of that nature. Low wages and the workers being exposed to a lot of troubling content means this could end up being a not very data ethicsy way of doing data ethics.</p>
</section>
<section id="what-are-the-consequences-of-innocuous-sentences-discussing-disability-being-supressed-in-online-moderation-contexts">
<h3>What are the consequences of “innocuous sentences discussing disability being supressed” in online moderation contexts?<a class="headerlink" href="#what-are-the-consequences-of-innocuous-sentences-discussing-disability-being-supressed-in-online-moderation-contexts" title="Permalink to this headline">#</a></h3>
<section id="context-and-nuance">
<h4>Context and Nuance<a class="headerlink" href="#context-and-nuance" title="Permalink to this headline">#</a></h4>
<p>Marginalised communities may choose to ‘reclaim’ certain langugage - automatic moderation may prevent them from doing so. There could be discourse in groups where words are reclaimed (e.g. the word <a class="reference external" href="https://en.wikipedia.org/wiki/Queer">“queer”</a> has had derogatory connotations in colloquial use but has been reclaimed as neutral/positive identifier). It doesn’t feel right to say you can’t use that.</p>
<p>Making places safe is very important, but if we try to automate it we solidify it. There is a removal of flexiblity in human judgement as at its base it’s a rule following system.</p>
<p>Communication broadens and complicates based on context. Who do we speak to? Children, adults, classes? How does the machine make a judgement? There a lot of human factors to consider.</p>
<p>We are opting out in the path of least resistance because there is so much content to moderate. Who gets to decide? It’s always going to be the people with the power not the people who are harmed.</p>
<p>There is some debate on person centered language versus other language. “Deaf person” versus “person who is deaf”. This is not necessarily agreed within communities. Wider group discussions have been used for “patients”, “service users”, “clients”. We may not be aware of the intention, maybe trying to do the right thing but not necessarily examine those intentions and motivations.</p>
<p>Language that is seemingly negative, like swearing, may not be perceived by the person as such but could have useful context. It might be typical language for some people in some groups/contexts and can also express heightened emotion.</p>
<p>Ismael was involved in a Genomics England’s Participant Panel who created a <a class="reference external" href="https://files.genomicsengland.co.uk/documents/Genomics-England-Language-Guide.pdf">guide on how
to talk about the people whose data
is curated at Genomics England</a>.</p>
<p>Rachael noted: Language evolves over time - meanings of certain words change with time. How can we ensure that language is not out of date?
This reflects the importance of having diverse teams. Diversity could mean a lot of different things - it might also mean knowledge of internet sub-cultures and what is or is not offensive. This isn’t always obvious. Paul’s student did work investigating online communities for disabled artists. They called themselves “crips”. Who says the word and in what context is really important to evaluating if its usage is appropriate.</p>
</section>
<section id="accessibility-issues-for-marginalised-groups">
<h4>Accessibility Issues for Marginalised Groups<a class="headerlink" href="#accessibility-issues-for-marginalised-groups" title="Permalink to this headline">#</a></h4>
<p>Already marginalised people could be prevented from commenting/tweeting/making videos. People will get around some of these checks to some extent with workarounds, e.g. unalive, le$$bean. How fast can sentiment analysis adapt? Is it faster than human moderators?</p>
<p>Is there an access issue? The time you need to make an input in any system can be more precious for disabled people. Disabled people are already at a disadvantage on these systems such as Twitter/Reddit/TikTok. Disabled people are less likely to report things as toxic because of this time pressure. People have a limited number of <span class="xref myst">“spoons” or “spell slots”</span>.</p>
<p>Getting feedback is difficult here by virtue of it being extra effort for those affected to self advocated For example in the case of “long covid” (3 months or longer). After 12 months, x% of people are recovered - or have they just stopped engaging with healthcare?</p>
<p>Deborah Lupton examines ‘the digital patient experience economy’ in <span class="xref myst">The Commodification of Patient Opinion</span> which is relevant to this discussion.</p>
<p>The concept of sexual harrassment in the workplace is an example of <a class="reference external" href="https://en.wikipedia.org/wiki/Epistemic_injustice">hermeneutic injustice</a> when someone’s experiences are not well understood — by themselves or by others. It can also be that you’ve internalised mistreatment so you can’t see it. Hermeneutics is the science of interpretation. A good book on this topic is: :sparkles: <a class="reference external" href="https://academic.oup.com/book/32817">Epistemic Injustice by Miranda Fricker</a></p>
<p>Silencing already marginalised voices by stopping people having a space to talk to speak to each other and stopping other people from hearing from them. It reinforces the medical model of disability versus the social model, creating a feedback loop.</p>
<p>Capitalism devalues disabled people because they are often less able to make money. If only there was something we could do about that…</p>
</section>
<section id="nlps-vs-human-moderators">
<h4>NLPs vs Human Moderators<a class="headerlink" href="#nlps-vs-human-moderators" title="Permalink to this headline">#</a></h4>
<p>What would be the ideal content moderation? At what stage do we have human input? Volunteer moderators vs paid moderators aided by automation.</p>
<p>When do we decide to use NLP versus a person? In which situations is it actually better to use a person? This becomes a conversation on who is allowed to say what and when. At the very least, the paper shows that this type of bias is likely to come up when training NLP models. It is very difficult to see how this could be managed well without humans. A good example is moderators on sub-reddits who decide on a set of rules about what is okay versus what is not okay.</p>
<p>Explainability does come into this too - how do we know what is being moderated and make this explicit. It’s important for there to be accountability. Systems become more and more complex, but this shouldn’t be confused with more sophistication. It makes it harder to explain what is or is not allowed.</p>
<p>Usage in a live context might be more useful rather than outsourcing decision making in different contexts? You end up with a language model that has learnt some kind of weird combination of rules that don’t actually apply globally and apply to lots of different contexts/rules.</p>
</section>
</section>
<section id="what-are-the-consequences-of-these-findings-given-the-growing-use-of-llms">
<h3>What are the consequences of these findings given the growing use of LLMs?<a class="headerlink" href="#what-are-the-consequences-of-these-findings-given-the-growing-use-of-llms" title="Permalink to this headline">#</a></h3>
<p>Not a question of safe/unsafe, just the scale is too great to moderate. People are using ChatGPT for everyday tasks. Should they be?</p>
<p>As we’ve already noted, language generally is full of values that change over time and not everyone agrees, so can we rely upon machines to resolve that for us?</p>
<p>One of us recalled an example of GPT 3.5 identifying women as nurse and men as doctor even when it doesn’t make grammatical sense.</p>
<p>People don’t know that these are problems that exist with LLMs. When you point them out, they’re obvious, but at the initial outset of LLMs, this is not something that comes up very often and that is a worry. Because it is proliferating so much, no one can be on top of what people are doing. <a class="reference external" href="https://www.bmj.com/content/372/bmj.n304">Does “AI” stand for augmenting inequality in the era of covid-19 healthcare</a></p>
<p>ChatGPT is retrainable so they’re using feedback from people to retrain the model but is this enough? There could be an arms race of people trying to train it to be toxic and another trying to train it to be wholesome.</p>
<p>The understanding that people have of these types of models, but in school we don’t really learn about data science just ICT or Maths. Maybe the next generation are going to be better equipped for this. There are people well past school, how do we educate them about this? Do they want to be educated on it? On ChatGPT, Ismael has made a <a class="reference external" href="https://github.com/KairoiAI/Resources/blob/main/Template-ChatGPT-policy.md">use policy for organisations/companies</a> to make sure their staff use it safely.</p>
<p>This is an existing problem with misinformation on the internet - for example everyone always believes Wikipedia without checking. ChatGPT doesn’t make it very obvious that it could be ‘lying’. There is a small warning that isn’t always presented. There should be more documentation for the users about the bias in the tool. This is legal in some countries, but not in others. E.g. Italy banned it.</p>
<p>How can we show people things might be wrong, in a way that companies (for profit) are willing to acknowledge publicly. (Bad for shareholders!)</p>
</section>
<section id="what-change-would-you-like-to-see-on-the-basis-of-this-piece-who-has-the-power-to-make-that-change">
<h3>What change would you like to see on the basis of this piece? Who has the power to make that change?<a class="headerlink" href="#what-change-would-you-like-to-see-on-the-basis-of-this-piece-who-has-the-power-to-make-that-change" title="Permalink to this headline">#</a></h3>
<p>Do we have to accept that these are fundamentally unsafe? It feels like an inevitable consequence that this is even more unacceptable.</p>
<p>Should we use people for moderation? If words are deemed inappropriate, should the user be able to use it if they claim the moderation (human or otherwise) is biased? Consult the groups that are most affected!</p>
<p><a class="reference external" href="https://www.tactcare.org.uk/content/uploads/2019/03/TACT-Language-that-cares-2019_online.pdf">“We are not mistakes on pages, we are awesome novels with unorthodox beginnings.”</a></p>
<p>Sentiment analysis often is not very accurate (such as the word “tory” being very toxic, but racial slurs not being in an analysis of abuse against MPs). A lot of language is very contextual, so it’s not even feasible to agree if something is “toxic” or not.</p>
<p>The comparison between “I am a person” and “I am a deaf person” is a bit unfair since people have different preference for person-first or not language. Language is very malleable which makes moderation more difficult: e.g. use of “unalive” on platforms such as tiktok in order to circumvent moderation.</p>
<p>We wondered how good or bad does something need to be to be used practically? How do you decide: how good is good enough? It would be nice to moderate out toxicity automatically, but it’s quite unlikely it’ll work perfectly. What would be good enough for these kinds of models to be used in moderating settings?</p>
</section>
</section>
<hr class="docutils" />
<section id="attendees">
<h2>Attendees<a class="headerlink" href="#attendees" title="Permalink to this headline">#</a></h2>
<p><strong>Name, Role, Affiliation, Where to find you, Emoji to describe your day</strong></p>
<ul class="simple">
<li><p>Natalie Zelenka, Data Scientist, University of Bristol, <a class="reference external" href="https://github.com/NatalieZelenka/">NatalieZelenka</a>, <a class="reference external" href="https://twitter.com/NatZelenka">&#64;NatZelenka</a></p></li>
<li><p>Nina Di Cara, Research Associate, University of Bristol, <a class="reference external" href="https://github.com/ninadicara/">ninadicara</a>, <a class="reference external" href="https://twitter.com/ninadicara">&#64;ninadicara</a></p></li>
<li><p>Huw Day, (Tired) PhDoer, University of Bristol, <a class="reference external" href="https://twitter.com/disco_huw">&#64;disco_huw</a></p></li>
<li><p>Euan Bennet, Lecturer, University of Glasgow, <a class="reference external" href="https://twitter.com/DrEuanBennet">&#64;DrEuanBennet</a></p></li>
<li><p>Noshin Mohamed - Practice Learning Reviewer in QA for children’</p></li>
<li><p>Ismael Kherroubi Garcia, AI Ethics &amp; Research Governance consultant, <a class="reference external" href="https://kairoi.uk">Kairoi</a>, <a class="reference external" href="https://www.linkedin.com/in/ismaelkherroubi/">LinkedIn</a></p></li>
<li><p>Zoë Turner, Senior Data Scientist, NHS Midlands and Lancashire CSU, <a class="reference external" href="https://github.com/Lextuga007">GitHub</a></p></li>
<li><p>Paul Matthews, Lecturer, UWE Bristol <a class="reference external" href="https://fetstudy.uwe.ac.uk/~pmatthew/">HomePage</a>,🦣<a class="reference external" href="https://scholar.social/&#64;paulusm">&#64;paulusm&#64;scholar.social</a></p></li>
<li><p><a class="reference external" href="https://www.linkedin.com/in/rachael-laidlaw/">Rachael Laidlaw</a>, PhD Student in Interactive Artificial Intelligence, University of Bristol</p></li>
</ul>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="03-05-23_writeup.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Data Ethics Club: Queer In AI: A Case Study in Community-Led Participatory AI</p>
      </div>
    </a>
    <a class="right-next"
       href="29-03-23_writeup.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Data Ethics Club: The Tech We Won’t Build</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion">Discussion</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#opening-thoughts">Opening thoughts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-the-consequences-of-innocuous-sentences-discussing-disability-being-supressed-in-online-moderation-contexts">What are the consequences of “innocuous sentences discussing disability being supressed” in online moderation contexts?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#context-and-nuance">Context and Nuance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#accessibility-issues-for-marginalised-groups">Accessibility Issues for Marginalised Groups</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#nlps-vs-human-moderators">NLPs vs Human Moderators</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-are-the-consequences-of-these-findings-given-the-growing-use-of-llms">What are the consequences of these findings given the growing use of LLMs?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-change-would-you-like-to-see-on-the-basis-of-this-piece-who-has-the-power-to-make-that-change">What change would you like to see on the basis of this piece? Who has the power to make that change?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#attendees">Attendees</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../../_sources/write_ups/2023/19-04-23_writeup.md.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>


  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">License: <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY-4.0</a></div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.5.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("G-93XN98JDFL");
pageTracker._trackPageview();
} catch(err) {}</script>

  </body>
</html>